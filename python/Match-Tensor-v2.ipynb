{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match tensor v2\n",
    "## NOTE: no where close to fully functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import merge, Dense, Input,Dropout, Embedding, LSTM, Bidirectional, Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.merge import dot, multiply, add, concatenate\n",
    "from keras.layers import Merge\n",
    "from keras.layers.core import Lambda,Reshape, Flatten\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.backend import transpose,batch_dot,expand_dims\n",
    "from keras import optimizers\n",
    "from HomeDepotCSVReader import HomeDepotReader\n",
    "import Utilities\n",
    "from DataPreprocessing import DataPreprocessing\n",
    "from Feature_Word2Vec import Feature_Word2Vec\n",
    "from AutomaticQueryExpansion import Word2VecQueryExpansion\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from FeatureEngineering import HomeDepotFeature\n",
    "from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_filename = '../data/train_play.csv'\n",
    "# test_filename = '../data/test_play.csv'\n",
    "# attribute_filename = '../data/attributes_play.csv'\n",
    "# description_filename = '../data/product_descriptions_play.csv'\n",
    "# word2vec_model_path='model/word2vec_play.model'\n",
    "# vocab_path='model/word2vec_play_vocab.json'\n",
    "# embeddings_path='model/embeddings_play.npz'\n",
    "\n",
    "train_filename = '../data/train.csv'\n",
    "test_filename = '../data/test.csv'\n",
    "soln_filename = '../data/solution.csv'\n",
    "attribute_filename = '../data/attributes.csv'\n",
    "description_filename = '../data/product_descriptions.csv'\n",
    "word2vec_model_path='model/word2vec.model'\n",
    "vocab_path='model/word2vec_vocab.json'\n",
    "embeddings_path='model/embeddings.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Tranforming labels...\n",
      "showing current values\n",
      "trainDF: ['id', 'product_uid', 'search_term', 'relevance']\n",
      "trainDF:    id  product_uid    search_term  relevance\n",
      "0   2       100001  angle bracket        3.0\n",
      "self.mergedLabelDF: ['relevance'] \n",
      " <class 'pandas.core.frame.DataFrame'> (74067, 1)    relevance\n",
      "0        3.0\n",
      "Old unique Labels: [ 1.    1.25  1.33  1.5   1.67  1.75  2.    2.25  2.33  2.5   2.67  2.75\n",
      "  3.  ]\n",
      "newLabels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Creating new column for training:  relevance_int\n",
      "===========Transform labels completed\n",
      "train_query_df: ['id', 'product_uid', 'search_term', 'relevance', 'relevance_int', 'product_idx']\n",
      "product_df: ['product_title', 'product_uid', 'product_description']\n",
      "attribute_df: ['product_uid', 'name', 'value']\n",
      "test_query_df: ['id', 'product_uid', 'search_term']\n"
     ]
    }
   ],
   "source": [
    "reader = HomeDepotReader()\n",
    "\n",
    "train_query_df, product_df, attribute_df, test_query_df = reader.getQueryProductAttributeDataFrame(train_filename,\n",
    "                                              test_filename,\n",
    "                                              attribute_filename,\n",
    "                                              description_filename)\n",
    "print(\"train_query_df:\",list(train_query_df))\n",
    "print(\"product_df:\", list(product_df))\n",
    "print(\"attribute_df:\", list(attribute_df))\n",
    "print(\"test_query_df:\", list(test_query_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform attribute into doc\n",
    "dp = DataPreprocessing()\n",
    "attribute_doc_df = dp.getAttributeDoc(attribute_df)\n",
    "#attribute_doc_df\n",
    "product_df=product_df.join(attribute_doc_df.set_index('product_uid'), on = 'product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# product_df['content'] = train_query_df['search_term'].map(str) + \" \" + \\\n",
    "#                         product_df['product_title'].map(str) + \" \" + \\\n",
    "#                         product_df['product_description'].map(str) + \" \" + \\\n",
    "#                         product_df['attr_json'].map(str)\n",
    "\n",
    "product_df['content'] = product_df['product_title'].map(str) + \" \" + \\\n",
    "                        product_df['product_description'].map(str) \n",
    "\n",
    "# ## no attribute\n",
    "# product_df['content'] = product_df['product_title'].map(str) + \" \" + \\\n",
    "#                         product_df['product_description'].map(str) \n",
    "        \n",
    "#product_df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### test data\n",
    "soln_df = pd.read_csv(soln_filename, delimiter=',', low_memory=False, encoding=\"ISO-8859-1\")\n",
    "test_private_df = dp.getGoldTestSet(test_query_df, soln_df, testsetoption='Private')#,savepath='../data/test_private_gold.csv')\n",
    "test_public_df = dp.getGoldTestSet(test_query_df, soln_df, testsetoption='Public')# savepath='../data/test_public_gold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spell correction\n",
      "Performing non-ascii removal\n",
      "Non-ascii clean on search_term took: 0.01 minutes\n",
      "Non-ascii clean on product_title took: 0.03 minutes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74067 entries, 0 to 74066\n",
      "Data columns (total 6 columns):\n",
      "id               74067 non-null int64\n",
      "product_uid      74067 non-null int64\n",
      "search_term      74067 non-null object\n",
      "relevance        74067 non-null float64\n",
      "relevance_int    74067 non-null int64\n",
      "product_idx      74067 non-null object\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 3.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_query_df = HomeDepotFeature().getFeature(train_query_df, product_df, attribute_df, test_private_df,\n",
    "                        features=\"spelling,nonascii\")\n",
    "#,stopwords,stemming\n",
    "#\"spelling,nonascii\" no diff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spell correction\n",
      "Performing non-ascii removal\n",
      "Non-ascii clean on search_term took: 0.01 minutes\n",
      "Non-ascii clean on product_title took: 0.03 minutes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78419 entries, 2 to 147405\n",
      "Data columns (total 4 columns):\n",
      "id             78419 non-null int64\n",
      "product_uid    78419 non-null int64\n",
      "search_term    78419 non-null object\n",
      "relevance      78419 non-null float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_private_df = HomeDepotFeature().getFeature(test_private_df, product_df, attribute_df, test_private_df,\n",
    "                        features=\"spelling,nonascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spell correction\n",
      "Performing non-ascii removal\n",
      "Non-ascii clean on search_term took: 0.0 minutes\n",
      "Non-ascii clean on product_title took: 0.03 minutes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33648 entries, 1 to 147404\n",
      "Data columns (total 4 columns):\n",
      "id             33648 non-null int64\n",
      "product_uid    33648 non-null int64\n",
      "search_term    33648 non-null object\n",
      "relevance      33648 non-null float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_public_df = HomeDepotFeature().getFeature(test_public_df, product_df, attribute_df, test_public_df,\n",
    "                        features=\"spelling,nonascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33648"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_public_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors\n",
    "def doc_to_wordlist( doc, remove_stopwords=False, remove_non_letters=False, remove_non_letters_numbers=True):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    #review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    if remove_non_letters:\n",
    "        doc = re.sub(\"[^a-zA-Z]\",\" \", doc)\n",
    "    # 2a. remove non-letters, numbers\n",
    "    if remove_non_letters_numbers:\n",
    "        doc = re.sub(\"[^a-zA-Z0-9]\",\" \", doc)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = doc.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)\n",
    "\n",
    "#print(len(doc_to_wordlist(product_df['content'][0],remove_stopwords=True)))\n",
    "#print(len(doc_to_wordlist(product_df['content'][0],remove_stopwords=False)))\n",
    "#product_df['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "# nltk.download()   \n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to split a doc into parsed sentences\n",
    "def doc_to_sentences( doc, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a doc into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(doc.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( doc_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pelican Water 10 GPM Whole House Carbon Water Filter System for Homes with 1-3 Bathrooms The PC600 Pelican Premium 10 GPM Whole House Carbon Water Filter System For Homes With 1-3 Bathrooms is a deluxe, high-capacity, virtually maintenance-free system that is easily installed in any home and has a 600,000/5-year capacity. Only the top rated valves and tanks are used in manufacturing each Pelican system, backed by an industry-leading limited lifetime parts warranty. Imagine spring-like water through every faucet of your home. Drink, bathe and shower in sparkling clean water with no more dry itchy skin or unpleasant odors from chemicals. The large diameter of the tank holds a significant amount of water filtration carbon media, increasing the overall performance and lifespan, and the replacement cost is a fraction of the cost of similar items. When it comes time to replace the filter, all you have to do is replace the media inside the tank, with no plumbing required and no need to replace the entire tank.Wrapped in premium stainless steel to ensure long life, durability and unsurpassed qualityPelican Carbon series filter features preloaded design that makes it ready to install, minimizes steps and saves timeMinimal filter/media change with the sediment pre-filter every six to nine months; tank 1 media every five years or 1,000,000 gallons; tank 2 media is lifetime media that needs no replacementIncludes sediment pre-filter system with mounting hardwareBacterial static media inhibits bacterial growthEnergy efficient; does not waste water and requires no electricity\n",
      "164\n",
      "['pelican', 'water', 'gpm', 'whole', 'house', 'carbon', 'water', 'filter', 'system', 'homes', 'bathrooms', 'pc', 'pelican', 'premium', 'gpm', 'whole', 'house', 'carbon', 'water', 'filter', 'system', 'homes', 'bathrooms', 'deluxe', 'high', 'capacity', 'virtually', 'maintenance', 'free', 'system', 'easily', 'installed', 'home', 'year', 'capacity', 'top', 'rated', 'valves', 'tanks', 'used', 'manufacturing', 'pelican', 'system', 'backed', 'industry', 'leading', 'limited', 'lifetime', 'parts', 'warranty', 'imagine', 'spring', 'like', 'water', 'every', 'faucet', 'home', 'drink', 'bathe', 'shower', 'sparkling', 'clean', 'water', 'dry', 'itchy', 'skin', 'unpleasant', 'odors', 'chemicals', 'large', 'diameter', 'tank', 'holds', 'significant', 'amount', 'water', 'filtration', 'carbon', 'media', 'increasing', 'overall', 'performance', 'lifespan', 'replacement', 'cost', 'fraction', 'cost', 'similar', 'items', 'comes', 'time', 'replace', 'filter', 'replace', 'media', 'inside', 'tank', 'plumbing', 'required', 'need', 'replace', 'entire', 'tank', 'wrapped', 'premium', 'stainless', 'steel', 'ensure', 'long', 'life', 'durability', 'unsurpassed', 'qualitypelican', 'carbon', 'series', 'filter', 'features', 'preloaded', 'design', 'makes', 'ready', 'install', 'minimizes', 'steps', 'saves', 'timeminimal', 'filter', 'media', 'change', 'sediment', 'pre', 'filter', 'every', 'six', 'nine', 'months', 'tank', 'media', 'every', 'five', 'years', 'gallons', 'tank', 'media', 'lifetime', 'media', 'needs', 'replacementincludes', 'sediment', 'pre', 'filter', 'system', 'mounting', 'hardwarebacterial', 'static', 'media', 'inhibits', 'bacterial', 'growthenergy', 'efficient', 'waste', 'water', 'requires', 'electricity']\n"
     ]
    }
   ],
   "source": [
    "print(product_df['content'][100])\n",
    "print(len(doc_to_wordlist(product_df['content'][100],remove_stopwords=True)))\n",
    "#print(len(doc_to_wordlist(product_df['content'][0],remove_stopwords=False)))\n",
    "print(doc_to_wordlist(product_df['content'][100],remove_stopwords=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(len(doc_to_sentences(product_df['content'][0],tokenizer,remove_stopwords=True)))\n",
    "# print(len(doc_to_sentences(product_df['content'][0],tokenizer,remove_stopwords=False)))\n",
    "# product_df['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from search string\n",
      "Parsing sentences from unlabeled set\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "query_sentences = []\n",
    "doc_sentences = []\n",
    "\n",
    "print(\"Parsing sentences from search string\")\n",
    "for query in train_query_df[\"search_term\"]:\n",
    "    query_sentences += [doc_to_wordlist(query, remove_stopwords=True)]\n",
    "\n",
    "print(\"Parsing sentences from unlabeled set\")\n",
    "for doc in product_df['content']:\n",
    "    doc_sentences += [doc_to_wordlist(doc, remove_stopwords=True)]\n",
    "\n",
    "sentences = query_sentences+doc_sentences    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198495"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-04 14:37:34,664 : INFO : collecting all words and their counts\n",
      "2017-04-04 14:37:34,665 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-04 14:37:34,675 : INFO : PROGRESS: at sentence #10000, processed 27305 words, keeping 3158 word types\n",
      "2017-04-04 14:37:34,683 : INFO : PROGRESS: at sentence #20000, processed 54948 words, keeping 4257 word types\n",
      "2017-04-04 14:37:34,702 : INFO : PROGRESS: at sentence #30000, processed 82693 words, keeping 4718 word types\n",
      "2017-04-04 14:37:34,711 : INFO : PROGRESS: at sentence #40000, processed 109758 words, keeping 4991 word types\n",
      "2017-04-04 14:37:34,720 : INFO : PROGRESS: at sentence #50000, processed 136925 words, keeping 5192 word types\n",
      "2017-04-04 14:37:34,730 : INFO : PROGRESS: at sentence #60000, processed 168240 words, keeping 5608 word types\n",
      "2017-04-04 14:37:34,744 : INFO : PROGRESS: at sentence #70000, processed 201592 words, keeping 5829 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-04 14:37:34,881 : INFO : PROGRESS: at sentence #80000, processed 820201 words, keeping 40419 word types\n",
      "2017-04-04 14:37:35,104 : INFO : PROGRESS: at sentence #90000, processed 1805194 words, keeping 72669 word types\n",
      "2017-04-04 14:37:35,318 : INFO : PROGRESS: at sentence #100000, processed 2783421 words, keeping 95967 word types\n",
      "2017-04-04 14:37:35,530 : INFO : PROGRESS: at sentence #110000, processed 3744111 words, keeping 115166 word types\n",
      "2017-04-04 14:37:35,746 : INFO : PROGRESS: at sentence #120000, processed 4723634 words, keeping 132548 word types\n",
      "2017-04-04 14:37:35,961 : INFO : PROGRESS: at sentence #130000, processed 5687008 words, keeping 146974 word types\n",
      "2017-04-04 14:37:36,181 : INFO : PROGRESS: at sentence #140000, processed 6625643 words, keeping 162974 word types\n",
      "2017-04-04 14:37:36,395 : INFO : PROGRESS: at sentence #150000, processed 7569832 words, keeping 176778 word types\n",
      "2017-04-04 14:37:36,609 : INFO : PROGRESS: at sentence #160000, processed 8509922 words, keeping 189195 word types\n",
      "2017-04-04 14:37:36,823 : INFO : PROGRESS: at sentence #170000, processed 9473773 words, keeping 200380 word types\n",
      "2017-04-04 14:37:37,039 : INFO : PROGRESS: at sentence #180000, processed 10432628 words, keeping 209884 word types\n",
      "2017-04-04 14:37:37,245 : INFO : PROGRESS: at sentence #190000, processed 11361881 words, keeping 220412 word types\n",
      "2017-04-04 14:37:37,422 : INFO : collected 228804 word types from a corpus of 12146266 raw words and 198495 sentences\n",
      "2017-04-04 14:37:37,423 : INFO : Loading a fresh vocabulary\n",
      "2017-04-04 14:37:39,885 : INFO : min_count=1 retains 228804 unique words (100% of original 228804, drops 0)\n",
      "2017-04-04 14:37:39,886 : INFO : min_count=1 leaves 12146266 word corpus (100% of original 12146266, drops 0)\n",
      "2017-04-04 14:37:40,950 : INFO : deleting the raw counts dictionary of 228804 items\n",
      "2017-04-04 14:37:40,955 : INFO : sample=0 downsamples 0 most-common words\n",
      "2017-04-04 14:37:40,956 : INFO : downsampling leaves estimated 12146266 word corpus (100.0% of prior 12146266)\n",
      "2017-04-04 14:37:40,957 : INFO : estimated required memory for 228804 words and 100 dimensions: 297445200 bytes\n",
      "2017-04-04 14:37:41,796 : INFO : resetting layer weights\n",
      "2017-04-04 14:37:46,228 : INFO : training model with 4 workers on 228804 vocabulary and 100 features, using sg=0 hs=0 sample=0 negative=5 window=10\n",
      "2017-04-04 14:37:46,229 : INFO : expecting 198495 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-04 14:37:47,263 : INFO : PROGRESS: at 7.81% examples, 553150 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:48,272 : INFO : PROGRESS: at 8.43% examples, 581862 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:49,280 : INFO : PROGRESS: at 9.04% examples, 585019 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:50,286 : INFO : PROGRESS: at 9.67% examples, 589546 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:51,292 : INFO : PROGRESS: at 10.31% examples, 594108 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:52,308 : INFO : PROGRESS: at 10.95% examples, 596193 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:53,321 : INFO : PROGRESS: at 11.60% examples, 599375 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:54,322 : INFO : PROGRESS: at 12.22% examples, 600156 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:55,338 : INFO : PROGRESS: at 12.88% examples, 601923 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 14:37:56,341 : INFO : PROGRESS: at 13.54% examples, 603155 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:57,367 : INFO : PROGRESS: at 14.20% examples, 602999 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:58,372 : INFO : PROGRESS: at 14.87% examples, 604627 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:37:59,389 : INFO : PROGRESS: at 15.53% examples, 604775 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:00,409 : INFO : PROGRESS: at 16.19% examples, 605463 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:01,410 : INFO : PROGRESS: at 16.84% examples, 606114 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:02,411 : INFO : PROGRESS: at 17.49% examples, 606724 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:03,435 : INFO : PROGRESS: at 18.14% examples, 607026 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 14:38:04,438 : INFO : PROGRESS: at 18.81% examples, 607456 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:05,479 : INFO : PROGRESS: at 19.49% examples, 607148 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:06,498 : INFO : PROGRESS: at 27.41% examples, 610011 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:07,531 : INFO : PROGRESS: at 28.09% examples, 610286 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:08,545 : INFO : PROGRESS: at 28.73% examples, 610621 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:09,548 : INFO : PROGRESS: at 29.36% examples, 610813 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:10,563 : INFO : PROGRESS: at 30.02% examples, 611497 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:11,605 : INFO : PROGRESS: at 30.68% examples, 611090 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:12,608 : INFO : PROGRESS: at 31.33% examples, 611574 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:13,608 : INFO : PROGRESS: at 31.98% examples, 612123 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:14,625 : INFO : PROGRESS: at 32.62% examples, 612272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:15,626 : INFO : PROGRESS: at 33.29% examples, 612741 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:16,638 : INFO : PROGRESS: at 33.96% examples, 612920 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:17,639 : INFO : PROGRESS: at 34.62% examples, 613019 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:18,645 : INFO : PROGRESS: at 35.29% examples, 613295 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:19,662 : INFO : PROGRESS: at 35.96% examples, 613376 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:20,671 : INFO : PROGRESS: at 36.61% examples, 613588 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:21,679 : INFO : PROGRESS: at 37.25% examples, 613243 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:22,684 : INFO : PROGRESS: at 37.90% examples, 613527 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:23,689 : INFO : PROGRESS: at 38.58% examples, 613789 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:24,700 : INFO : PROGRESS: at 39.26% examples, 613934 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:25,735 : INFO : PROGRESS: at 39.94% examples, 613721 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:26,736 : INFO : PROGRESS: at 47.87% examples, 615524 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:27,758 : INFO : PROGRESS: at 48.50% examples, 615232 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-04 14:38:28,770 : INFO : PROGRESS: at 49.14% examples, 615307 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:29,772 : INFO : PROGRESS: at 49.78% examples, 615288 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:30,788 : INFO : PROGRESS: at 50.43% examples, 615322 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:31,795 : INFO : PROGRESS: at 51.09% examples, 615456 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:32,804 : INFO : PROGRESS: at 51.73% examples, 615579 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:33,807 : INFO : PROGRESS: at 52.38% examples, 615758 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:34,813 : INFO : PROGRESS: at 53.02% examples, 615707 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:35,817 : INFO : PROGRESS: at 53.70% examples, 615858 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:36,820 : INFO : PROGRESS: at 54.37% examples, 616012 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:37,822 : INFO : PROGRESS: at 55.02% examples, 615982 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:38,823 : INFO : PROGRESS: at 55.68% examples, 615970 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:39,851 : INFO : PROGRESS: at 56.36% examples, 616042 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:40,860 : INFO : PROGRESS: at 57.01% examples, 616123 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:41,894 : INFO : PROGRESS: at 57.69% examples, 616291 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:42,923 : INFO : PROGRESS: at 58.35% examples, 616142 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:43,948 : INFO : PROGRESS: at 59.05% examples, 616382 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:44,951 : INFO : PROGRESS: at 59.69% examples, 615669 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:45,970 : INFO : PROGRESS: at 67.63% examples, 616511 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:46,987 : INFO : PROGRESS: at 68.26% examples, 616663 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:47,994 : INFO : PROGRESS: at 68.92% examples, 616910 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:49,006 : INFO : PROGRESS: at 69.56% examples, 616936 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:50,008 : INFO : PROGRESS: at 70.21% examples, 617053 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:51,012 : INFO : PROGRESS: at 70.87% examples, 617167 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:52,025 : INFO : PROGRESS: at 71.52% examples, 617176 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:53,045 : INFO : PROGRESS: at 72.15% examples, 616977 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:54,055 : INFO : PROGRESS: at 72.82% examples, 617176 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:55,064 : INFO : PROGRESS: at 73.48% examples, 617221 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:56,078 : INFO : PROGRESS: at 74.12% examples, 616802 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:57,090 : INFO : PROGRESS: at 74.72% examples, 615832 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:58,102 : INFO : PROGRESS: at 75.39% examples, 615868 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:38:59,110 : INFO : PROGRESS: at 76.06% examples, 616083 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:00,112 : INFO : PROGRESS: at 76.72% examples, 616207 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:01,124 : INFO : PROGRESS: at 77.39% examples, 616370 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:02,138 : INFO : PROGRESS: at 78.05% examples, 616518 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:03,155 : INFO : PROGRESS: at 78.74% examples, 616633 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:04,199 : INFO : PROGRESS: at 79.44% examples, 616664 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:05,203 : INFO : PROGRESS: at 86.06% examples, 617402 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:06,208 : INFO : PROGRESS: at 88.02% examples, 617227 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:07,220 : INFO : PROGRESS: at 88.66% examples, 617251 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:08,221 : INFO : PROGRESS: at 89.30% examples, 617344 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:09,225 : INFO : PROGRESS: at 89.93% examples, 617297 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:10,250 : INFO : PROGRESS: at 90.57% examples, 617099 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:11,254 : INFO : PROGRESS: at 91.23% examples, 617183 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:12,256 : INFO : PROGRESS: at 91.88% examples, 617272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:13,269 : INFO : PROGRESS: at 92.53% examples, 617391 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:14,278 : INFO : PROGRESS: at 93.19% examples, 617442 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:15,286 : INFO : PROGRESS: at 93.86% examples, 617477 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:16,294 : INFO : PROGRESS: at 94.54% examples, 617513 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:17,297 : INFO : PROGRESS: at 95.21% examples, 617683 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:18,314 : INFO : PROGRESS: at 95.89% examples, 617668 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:19,315 : INFO : PROGRESS: at 96.55% examples, 617861 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:20,329 : INFO : PROGRESS: at 97.20% examples, 617754 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:21,335 : INFO : PROGRESS: at 97.86% examples, 617910 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:22,340 : INFO : PROGRESS: at 98.55% examples, 618060 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:23,348 : INFO : PROGRESS: at 99.23% examples, 618095 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:24,351 : INFO : PROGRESS: at 99.91% examples, 618159 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 14:39:24,431 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-04 14:39:24,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-04 14:39:24,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-04 14:39:24,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-04 14:39:24,483 : INFO : training on 60731330 raw words (60731330 effective words) took 98.2s, 618154 effective words/s\n",
      "2017-04-04 14:39:24,605 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-04 14:39:27,080 : INFO : saving Word2Vec object under model/word2vec.model, separately None\n",
      "2017-04-04 14:39:27,081 : INFO : storing np array 'syn0' to model/word2vec.model.wv.syn0.npy\n",
      "2017-04-04 14:39:27,151 : INFO : not storing attribute syn0norm\n",
      "2017-04-04 14:39:27,152 : INFO : storing np array 'syn1neg' to model/word2vec.model.syn1neg.npy\n",
      "2017-04-04 14:39:27,775 : INFO : not storing attribute cum_table\n",
      "2017-04-04 14:39:28,627 : INFO : saved model/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 100#50#300    # Word vector dimensionality                      \n",
    "min_word_count = 1#5#40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 0 #1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "word2vec_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "word2vec_model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "#model_name = \"300features_40minwords_10context\"\n",
    "word2vec_model.save(word2vec_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228804\n"
     ]
    }
   ],
   "source": [
    "print(len(word2vec_model.wv.vocab))\n",
    "#word2vec_model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hardwoods', 0.5958949327468872), ('pine', 0.5781776905059814), ('hardwood', 0.5520675778388977)]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model.most_similar('wood', [], 3))\n",
    "#print(word2vec_model.most_similar('temperature'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #w2v=Feature_Word2Vec(modelFilename=word2vec_model_path)#modelFilename=word2vec_model_path\n",
    "# w2v=Feature_Word2Vec()\n",
    "# #sentences=w2v.convertDFIntoSentences(product_df,'content')\n",
    "# #print(sentences)\n",
    "# w2v.trainModel(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(w2v.model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# w2vExpand=Word2VecQueryExpansion(modelFilename=word2vec_model_path)\n",
    "# query=\"cooking\"\n",
    "# print(\"Expanding query: \")\n",
    "# print(w2vExpand.getExpandedQuery(query,maxNoOfAdditionalWords=2,minSimilarityLevel=0.65,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(w2v.getVectorFromWord('wood'))\n",
    "# print(w2v.getSimilarWordVectors('wood',5))\n",
    "# print(len(w2v.getVectorFromWord('wood')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embeddings to keras\n",
    "http://ben.bolte.cc/resources/embeddings/embeddings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vocab = dict([(k, v.index) for k, v in w2v.model.wv.vocab.items()])\n",
    "#vocab = dict([(k, v.index) for k, v in word2vec_model.wv.vocab.items()])\n",
    "vocab = dict([(k, v.index+1) for k, v in word2vec_model.wv.vocab.items()]) # Leave room for <pad>\n",
    "vocab['<PAD>']=0\n",
    "with open(vocab_path, 'w') as f:\n",
    "    f.write(json.dumps(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights = w2v.model.wv.syn0\n",
    "weights = word2vec_model.wv.syn0\n",
    "np.save(open(embeddings_path, 'wb'), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vocab(vocab_path):\n",
    "    \"\"\"\n",
    "    Load word -> index and index -> word mappings\n",
    "    :param vocab_path: where the word-index map is saved\n",
    "    :return: word2idx, idx2word\n",
    "    \"\"\"\n",
    "\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    word2idx = data\n",
    "    idx2word = dict([(v, k) for k, v in data.items()])\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx, idx2word = load_vocab(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2vec_embedding_layer(embeddings_path):\n",
    "    \"\"\"\n",
    "    Generate an embedding layer word2vec embeddings\n",
    "    :param embeddings_path: where the embeddings are saved (as a numpy file)\n",
    "    :return: the generated embedding layer\n",
    "    \"\"\"\n",
    "\n",
    "    saved_weights = np.load(open(embeddings_path, 'rb'))\n",
    "    padding_weight = np.zeros(num_features)\n",
    "    padding_weight=np.expand_dims(padding_weight,axis=0)\n",
    "    weights=np.concatenate((padding_weight,saved_weights), axis=0)\n",
    "    layer = Embedding(input_dim=weights.shape[0], output_dim=weights.shape[1], weights=[weights],mask_zero=True, trainable=False)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a = np.load(open(embeddings_path, 'rb'))\n",
    "# b = np.zeros(50)\n",
    "# b=np.expand_dims(b,axis=0)\n",
    "# b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c=np.concatenate((b,a), axis=0)\n",
    "# c[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# idx2word = []\n",
    "# idx2word=[dict([(v, k) for k, v in word2idx.items()])]\n",
    "# idx2word.insert(0, '<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD>'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_tokens=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variable arguments are passed to gensim's word2vec model\n",
    "# if options.train:\n",
    "#     print('Training Word2Vec...')\n",
    "#     create_embeddings(options.data, options.embeddings, options.vocab, size=100, min_count=5, window=5, sg=1, iter=25)\n",
    "\n",
    "word2idx, idx2word = load_vocab(vocab_path)\n",
    "\n",
    "if print_tokens:\n",
    "    print('Tokens:', ', '.join(word2idx.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228805"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo need to pass in word2idx\n",
    "def convert_word2idx(word,verbose=False):\n",
    "    if verbose:\n",
    "        print(\"word: {}\".format(word))\n",
    "    if word not in word2idx.keys():\n",
    "        return 0\n",
    "    else:\n",
    "        return word2idx[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8649\n",
      "10\n",
      "1290\n",
      "1448\n",
      "519\n",
      "1013\n",
      "10\n",
      "231\n",
      "38\n",
      "1184\n",
      "1098\n",
      "2808\n",
      "8649\n",
      "166\n",
      "1290\n",
      "1448\n",
      "519\n",
      "1013\n",
      "10\n",
      "231\n",
      "38\n",
      "1184\n",
      "1098\n",
      "1510\n",
      "16\n",
      "240\n",
      "880\n",
      "253\n",
      "69\n",
      "38\n",
      "86\n",
      "212\n",
      "11\n",
      "49\n",
      "240\n",
      "52\n",
      "481\n",
      "1284\n",
      "3007\n",
      "20\n",
      "1238\n",
      "8649\n",
      "38\n",
      "990\n",
      "603\n",
      "1395\n",
      "126\n",
      "136\n",
      "399\n",
      "48\n",
      "6117\n",
      "609\n",
      "268\n",
      "10\n",
      "356\n",
      "128\n",
      "11\n",
      "5660\n",
      "8138\n",
      "53\n",
      "4088\n",
      "32\n",
      "10\n",
      "252\n",
      "14905\n",
      "1864\n",
      "8362\n",
      "1632\n",
      "1393\n",
      "133\n",
      "429\n",
      "550\n",
      "847\n",
      "4095\n",
      "1263\n",
      "10\n",
      "1344\n",
      "1013\n",
      "1382\n",
      "3682\n",
      "1088\n",
      "103\n",
      "5542\n",
      "270\n",
      "487\n",
      "2983\n",
      "487\n",
      "1913\n",
      "342\n",
      "159\n",
      "98\n",
      "948\n",
      "231\n",
      "948\n",
      "1382\n",
      "318\n",
      "550\n",
      "788\n",
      "214\n",
      "138\n",
      "948\n",
      "1015\n",
      "550\n",
      "2363\n",
      "166\n",
      "73\n",
      "7\n",
      "401\n",
      "76\n",
      "140\n",
      "102\n",
      "4998\n",
      "52414\n",
      "1013\n",
      "195\n",
      "231\n",
      "18\n",
      "23255\n",
      "8\n",
      "161\n",
      "261\n",
      "122\n",
      "2460\n",
      "1811\n",
      "1533\n",
      "52415\n",
      "231\n",
      "1382\n",
      "792\n",
      "3014\n",
      "190\n",
      "231\n",
      "356\n",
      "1788\n",
      "5935\n",
      "1830\n",
      "550\n",
      "1382\n",
      "356\n",
      "1396\n",
      "206\n",
      "3147\n",
      "550\n",
      "1382\n",
      "136\n",
      "1382\n",
      "384\n",
      "34142\n",
      "3014\n",
      "190\n",
      "231\n",
      "38\n",
      "204\n",
      "52416\n",
      "3850\n",
      "1382\n",
      "4064\n",
      "5466\n",
      "40914\n",
      "331\n",
      "972\n",
      "10\n",
      "515\n",
      "2130\n"
     ]
    }
   ],
   "source": [
    "#convert_word2idx('bracket')\n",
    "for word in doc_sentences[100]:\n",
    "    idx=convert_word2idx(word)\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_sent2idx(sentences):\n",
    "    query_word2vec_idx_list=[]\n",
    "    queries=sentences #w2v.convertDFIntoSentences(df,col)\n",
    "    print(len(queries))\n",
    "    for query in queries:\n",
    "        idx_list = []\n",
    "        for word in query:\n",
    "#             if word not in word2idx.keys():\n",
    "#                 idx_list+=[0]#[len(word2idx.keys())] # use last as special key #TODO: well we need to fix this. Using 0 for now so it's in range To OOV or something random\n",
    "#             else:\n",
    "#                 idx_list+=[word2idx[word]]\n",
    "            idx_list+=[convert_word2idx(word)]\n",
    "        query_word2vec_idx_list+=[idx_list]\n",
    "        #print(\"=====\")\n",
    "        #print(idx_list)\n",
    "        #print(\"=====\")\n",
    "    return query_word2vec_idx_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74067\n"
     ]
    }
   ],
   "source": [
    "#query_word2vec_idx_list = query_sent2idx(train_query_df['search_term'])\n",
    "query_word2vec_idx_list = query_sent2idx(query_sentences)\n",
    "#print(query_word2vec_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def doc_sent2idx(df,col):\n",
    "#     doc_word2vec_idx_list=[]\n",
    "#     for row in df.iteritems():\n",
    "#         a=w2v.convertDFIntoSentences(row,col)\n",
    "#         print(a)\n",
    "# #    print(len(queries))\n",
    "# #     for query in queries:\n",
    "# #         idx_list = []\n",
    "# #         for word in query:\n",
    "# #             if word not in word2idx.keys():\n",
    "# #                 idx_list+=[len(word2idx.keys())] # use last as special key\n",
    "# #             else:\n",
    "# #                 idx_list+=[word2idx[word]]\n",
    "# #         query_word2vec_idx_list+=[idx_list]\n",
    "# #         print(\"=====\")\n",
    "# #         print(idx_list)\n",
    "# #         print(\"=====\")\n",
    "#     return doc_word2vec_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74067\n"
     ]
    }
   ],
   "source": [
    "#TODO: this is fucked. just bodge for testing nn\n",
    "#doc_word2vec_idx_list = query_sent2idx(product_df,'product_title')\n",
    "joined_df=train_query_df.join(product_df.set_index('product_uid'), on='product_uid')\n",
    "\n",
    "joined_doc_sentences=[]\n",
    "for doc in joined_df['content']:\n",
    "    joined_doc_sentences += [doc_to_wordlist(doc, remove_stopwords=True)]\n",
    "    \n",
    "doc_word2vec_idx_list = query_sent2idx(joined_doc_sentences)\n",
    "#print(doc_word2vec_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74067"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_doc_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5293,\n",
       " 4227,\n",
       " 87,\n",
       " 2435,\n",
       " 173,\n",
       " 769,\n",
       " 1792,\n",
       " 1189,\n",
       " 2435,\n",
       " 1792,\n",
       " 473,\n",
       " 926,\n",
       " 356,\n",
       " 11,\n",
       " 968,\n",
       " 1104,\n",
       " 877,\n",
       " 1595,\n",
       " 810,\n",
       " 55,\n",
       " 2342,\n",
       " 506,\n",
       " 15,\n",
       " 87,\n",
       " 325,\n",
       " 801,\n",
       " 849,\n",
       " 98,\n",
       " 77,\n",
       " 4,\n",
       " 1572,\n",
       " 59,\n",
       " 598,\n",
       " 21598,\n",
       " 55,\n",
       " 2342,\n",
       " 1595,\n",
       " 810,\n",
       " 55,\n",
       " 2342,\n",
       " 801,\n",
       " 849,\n",
       " 98,\n",
       " 139,\n",
       " 114539,\n",
       " 114540,\n",
       " 1572,\n",
       " 59,\n",
       " 1887,\n",
       " 1053,\n",
       " 24184,\n",
       " 94,\n",
       " 35,\n",
       " 176]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word2vec_idx_list[100]\n",
    "#query_word2vec_idx_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # cosine similarity model\n",
    "# print('Building model...')\n",
    "# input_a = Input(shape=(1,), dtype='int32', name='input_a')\n",
    "# input_b = Input(shape=(1,), dtype='int32', name='input_b')\n",
    "# embeddings = word2vec_embedding_layer(embeddings_path)\n",
    "# embedding_a = embeddings(input_a)\n",
    "# embedding_b = embeddings(input_b)\n",
    "# similarity = merge([embedding_a, embedding_b], mode='cos', dot_axes=2)\n",
    "# model = Model(input=[input_a, input_b], output=similarity)\n",
    "# model.compile(optimizer='sgd', loss='mse') # optimizer and loss don't matter\n",
    "\n",
    "\n",
    "# word_a = 'wood'#raw_input('First word: ')\n",
    "# if word_a not in word2idx:\n",
    "#     print('\"%s\" is not in the index' % word_a)\n",
    "# word_b = 'fan'#raw_input('Second word: ')\n",
    "# if word_b not in word2idx:\n",
    "#     print('\"%s\" is not in the index' % word_b)\n",
    "# output = model.predict([np.asarray([word2idx[word_a]]), np.asarray([word2idx[word_b]])])\n",
    "# print('%f' % output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "6\n",
      "21\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "query_min_len = len(min(query_word2vec_idx_list,key=len)) #400 # todo: confirm this is sensible\n",
    "doc_min_len = len(min(doc_word2vec_idx_list,key=len)) #400 # todo: confirm this is sensible\n",
    "query_max_len = 6 #covers 95.74% of the search lengths (see data exploration)\n",
    "# find longest sub list\n",
    "doc_max_len = 100 #len(max(doc_word2vec_idx_list,key=len)) #400 # todo: confirm this is sensible\n",
    "print(doc_max_len)\n",
    "print(query_max_len)\n",
    "print(doc_min_len)\n",
    "print(query_min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths=[]\n",
    "for i in doc_word2vec_idx_list:\n",
    "    lengths+=[len(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.56000000e+02,   3.86600000e+03,   7.71000000e+03,\n",
       "          1.03650000e+04,   8.56200000e+03,   8.24900000e+03,\n",
       "          6.47000000e+03,   6.07100000e+03,   4.60200000e+03,\n",
       "          3.24100000e+03,   3.14600000e+03,   2.23600000e+03,\n",
       "          1.99000000e+03,   1.55000000e+03,   1.20900000e+03,\n",
       "          1.04300000e+03,   7.84000000e+02,   5.66000000e+02,\n",
       "          3.57000000e+02,   3.56000000e+02,   2.65000000e+02,\n",
       "          2.18000000e+02,   1.43000000e+02,   1.29000000e+02,\n",
       "          1.28000000e+02,   7.30000000e+01,   8.70000000e+01,\n",
       "          6.10000000e+01,   2.60000000e+01,   5.30000000e+01,\n",
       "          3.60000000e+01,   1.30000000e+01,   2.60000000e+01,\n",
       "          7.00000000e+00,   1.00000000e+01,   1.70000000e+01,\n",
       "          2.00000000e+00,   1.40000000e+01,   2.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   3.00000000e+00,\n",
       "          0.00000000e+00,   8.00000000e+00,   2.00000000e+00,\n",
       "          0.00000000e+00,   6.00000000e+00,   1.00000000e+00,\n",
       "          6.00000000e+00,   1.00000000e+00]),\n",
       " array([  21.  ,   32.56,   44.12,   55.68,   67.24,   78.8 ,   90.36,\n",
       "         101.92,  113.48,  125.04,  136.6 ,  148.16,  159.72,  171.28,\n",
       "         182.84,  194.4 ,  205.96,  217.52,  229.08,  240.64,  252.2 ,\n",
       "         263.76,  275.32,  286.88,  298.44,  310.  ,  321.56,  333.12,\n",
       "         344.68,  356.24,  367.8 ,  379.36,  390.92,  402.48,  414.04,\n",
       "         425.6 ,  437.16,  448.72,  460.28,  471.84,  483.4 ,  494.96,\n",
       "         506.52,  518.08,  529.64,  541.2 ,  552.76,  564.32,  575.88,\n",
       "         587.44,  599.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEV1JREFUeJzt3X+s3XV9x/Hnay0gighI07AW1y5rXIBMkYbVaYyRbVQx\nlj820iWOZmH0D9iG2xJTZjKzP5rAsjhHMkiIKGU6WYNuNCLbsGrM/gC8CA5K7ahSpF2hVaeoyVDw\nvT/Op+5wP7f8uOf2nntun4/k5HzO+/v9nvt5p4VXP9/vOd+bqkKSpGG/MO4JSJIWHsNBktQxHCRJ\nHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJnaXjnsBsnXnmmbVq1apxT0OSJsoDDzzwnapa9lL7\nTWw4rFq1iqmpqXFPQ5ImSpInXs5+nlaSJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lS\nx3CQJHUm9hvSC8WqLXfNWN933SXzPBNJmjuuHCRJHcNBktR5yXBI8vEkh5I8MlQ7I8k9SR5rz6cP\nbbs2yd4ke5JcPFS/IMnDbdsNSdLqJyX5p1a/L8mquW1RkvRKvZyVw63A+mm1LcDOqloD7GyvSXIO\nsBE4tx1zY5Il7ZibgCuBNe1x5D2vAP6nqn4F+Fvg+tk2I0maGy8ZDlX1FeB708obgG1tvA24dKh+\ne1U9W1WPA3uBC5OcBZxaVfdWVQG3TTvmyHvdAVx0ZFUhSRqP2V5zWF5VB9v4KWB5G68Anhzab3+r\nrWjj6fUXHFNVzwE/AF4/y3lJkubAyBek20qg5mAuLynJ5iRTSaYOHz48Hz9Sko5Lsw2Hp9upItrz\noVY/AJw9tN/KVjvQxtPrLzgmyVLgdcB3Z/qhVXVzVa2tqrXLlr3kb7mTJM3SbMNhB7CpjTcBdw7V\nN7ZPIK1mcOH5/nYK6pkk69r1hMunHXPkvX4H+GJbjUiSxuQlvyGd5NPAO4Ezk+wHPgxcB2xPcgXw\nBHAZQFXtSrIdeBR4Dri6qp5vb3UVg08+nQzc3R4AtwD/kGQvgwvfG+ekM0nSrL1kOFTV7x1l00VH\n2X8rsHWG+hRw3gz1/wV+96XmIUmaP35DWpLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwk\nSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3D\nQZLUMRwkSR3DQZLUMRwkSZ2l457AYrVqy10z1vddd8k8z0SSXjlXDpKkjuEgSeoYDpKkjuEgSeoY\nDpKkjp9Wmmd+iknSJBhp5ZDkT5PsSvJIkk8neVWSM5Lck+Sx9nz60P7XJtmbZE+Si4fqFyR5uG27\nIUlGmZckaTSzDockK4A/AdZW1XnAEmAjsAXYWVVrgJ3tNUnOadvPBdYDNyZZ0t7uJuBKYE17rJ/t\nvCRJoxv1msNS4OQkS4FXA/8NbAC2te3bgEvbeANwe1U9W1WPA3uBC5OcBZxaVfdWVQG3DR0jSRqD\nWYdDVR0A/gb4NnAQ+EFV/TuwvKoOtt2eApa38QrgyaG32N9qK9p4el2SNCajnFY6ncFqYDXwi8Br\nkrx/eJ+2EqiRZvjCn7k5yVSSqcOHD8/V20qSphnltNJvAo9X1eGq+inwWeA3gKfbqSLa86G2/wHg\n7KHjV7bagTaeXu9U1c1Vtbaq1i5btmyEqUuSXswo4fBtYF2SV7dPF10E7AZ2AJvaPpuAO9t4B7Ax\nyUlJVjO48Hx/OwX1TJJ17X0uHzpGkjQGs/6eQ1Xdl+QO4GvAc8CDwM3AKcD2JFcATwCXtf13JdkO\nPNr2v7qqnm9vdxVwK3AycHd7SJLGZKQvwVXVh4EPTys/y2AVMdP+W4GtM9SngPNGmYskae54+wxJ\nUsfbZ7wMR7vlhSQtVq4cJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS\n1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEc\nJEkdw0GS1Fk67gloYNWWu2as77vuknmeiSS5cpAkzcBwkCR1DAdJUsdwkCR1RgqHJKcluSPJN5Ls\nTvLWJGckuSfJY+359KH9r02yN8meJBcP1S9I8nDbdkOSjDIvSdJoRl05/B3wr1X1q8CbgN3AFmBn\nVa0BdrbXJDkH2AicC6wHbkyypL3PTcCVwJr2WD/ivCRJI5h1OCR5HfAO4BaAqvpJVX0f2ABsa7tt\nAy5t4w3A7VX1bFU9DuwFLkxyFnBqVd1bVQXcNnSMJGkMRvmew2rgMPCJJG8CHgCuAZZX1cG2z1PA\n8jZeAdw7dPz+VvtpG0+vC7//IGk8RjmttBR4C3BTVZ0P/Jh2CumIthKoEX7GCyTZnGQqydThw4fn\n6m0lSdOMEg77gf1VdV97fQeDsHi6nSqiPR9q2w8AZw8dv7LVDrTx9Hqnqm6uqrVVtXbZsmUjTF2S\n9GJmHQ5V9RTwZJI3ttJFwKPADmBTq20C7mzjHcDGJCclWc3gwvP97RTUM0nWtU8pXT50jCRpDEa9\nt9IfA59KciLwLeAPGATO9iRXAE8AlwFU1a4k2xkEyHPA1VX1fHufq4BbgZOBu9tDkjQmI4VDVT0E\nrJ1h00VH2X8rsHWG+hRw3ihzkSTNHb8hLUnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6S\npI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7h\nIEnqGA6SpI7hIEnqLB33BDQ7q7bcNWN933WXzPNMJC1GrhwkSR3DQZLUMRwkSR3DQZLUMRwkSR3D\nQZLUMRwkSZ2RwyHJkiQPJvlce31GknuSPNaeTx/a99oke5PsSXLxUP2CJA+3bTckyajzkiTN3lys\nHK4Bdg+93gLsrKo1wM72miTnABuBc4H1wI1JlrRjbgKuBNa0x/o5mJckaZZGCockK4FLgI8NlTcA\n29p4G3DpUP32qnq2qh4H9gIXJjkLOLWq7q2qAm4bOkaSNAajrhw+CnwQ+NlQbXlVHWzjp4DlbbwC\neHJov/2ttqKNp9clSWMy63BI8l7gUFU9cLR92kqgZvszZviZm5NMJZk6fPjwXL2tJGmaUVYObwPe\nl2QfcDvwriSfBJ5up4poz4fa/geAs4eOX9lqB9p4er1TVTdX1dqqWrts2bIRpi5JejGzDoequraq\nVlbVKgYXmr9YVe8HdgCb2m6bgDvbeAewMclJSVYzuPB8fzsF9UySde1TSpcPHSNJGoNjccvu64Dt\nSa4AngAuA6iqXUm2A48CzwFXV9Xz7ZirgFuBk4G722PeHe022JJ0vJmTcKiqLwNfbuPvAhcdZb+t\nwNYZ6lPAeXMxF0nS6PyGtCSpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhI\nkjrH4t5KGqOj3R9q33WXzPNMJE0yVw6SpI4rh+OEKwpJr4QrB0lSx3CQJHUMB0lSx3CQJHUMB0lS\nx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx98E\nd5zzN8RJmsmsVw5Jzk7ypSSPJtmV5JpWPyPJPUkea8+nDx1zbZK9SfYkuXiofkGSh9u2G5JktLYk\nSaMY5bTSc8CfV9U5wDrg6iTnAFuAnVW1BtjZXtO2bQTOBdYDNyZZ0t7rJuBKYE17rB9hXpKkEc06\nHKrqYFV9rY1/COwGVgAbgG1tt23ApW28Abi9qp6tqseBvcCFSc4CTq2qe6uqgNuGjpEkjcGcXJBO\nsgo4H7gPWF5VB9ump4DlbbwCeHLosP2ttqKNp9clSWMy8gXpJKcAnwE+UFXPDF8uqKpKUqP+jKGf\ntRnYDPCGN7xhrt5WM/BCtXR8G2nlkOQEBsHwqar6bCs/3U4V0Z4PtfoB4Oyhw1e22oE2nl7vVNXN\nVbW2qtYuW7ZslKlLkl7EKJ9WCnALsLuqPjK0aQewqY03AXcO1TcmOSnJagYXnu9vp6CeSbKuvefl\nQ8dIksZglNNKbwN+H3g4yUOt9hfAdcD2JFcATwCXAVTVriTbgUcZfNLp6qp6vh13FXArcDJwd3tI\nksZk1uFQVf8BHO37CBcd5ZitwNYZ6lPAebOdiyRpbnn7DElSx3CQJHUMB0lSx3CQJHW8K6tekaN9\nOQ78gpy0mLhykCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsePsmrO+DsgpMXDlYMkqWM4SJI6nlbS\nMefpJmnyuHKQJHUMB0lSx3CQJHUMB0lSxwvSGhsvVEsLlysHSVLHcJAkdQwHSVLHaw5acLwWIY2f\nKwdJUsdwkCR1DAdJUsdwkCR1jssL0ke74KmF7ZX+uXkBW5o9Vw6SpM5xuXLQ8cGVhjR7C2blkGR9\nkj1J9ibZMu75SNLxbEGsHJIsAf4e+C1gP/DVJDuq6tHxzkzHk7m6FuUKRIvBgggH4EJgb1V9CyDJ\n7cAGwHDQxJlNyBgoWmgWSjisAJ4cer0f+PUxzUWad8f6E3RHC5+5ulWJtzxZfBZKOLwsSTYDm9vL\nHyXZM7T5TOA78z+rY8qeFr6J6CfXv6Ldz8z1c9PTK/y5x9JE/Dm9AqP080svZ6eFEg4HgLOHXq9s\ntReoqpuBm2d6gyRTVbX22ExvPOxp4Vts/YA9TYL56GehfFrpq8CaJKuTnAhsBHaMeU6SdNxaECuH\nqnouyR8B/wYsAT5eVbvGPC1JOm4tiHAAqKrPA58f4S1mPN004exp4Vts/YA9TYJj3k+q6lj/DEnS\nhFko1xwkSQvIogiHSbz1RpKPJzmU5JGh2hlJ7knyWHs+fWjbta2/PUkuHs+sX1ySs5N8KcmjSXYl\nuabVJ7KvJK9Kcn+Sr7d+/qrVJ7KfYUmWJHkwyefa64nuKcm+JA8neSjJVKtNbE9JTktyR5JvJNmd\n5K3z3k9VTfSDwQXsbwK/DJwIfB04Z9zzehnzfgfwFuCRodpfA1vaeAtwfRuf0/o6CVjd+l0y7h5m\n6Oks4C1t/Frgv9rcJ7IvIMApbXwCcB+wblL7mdbbnwH/CHxukfzd2wecOa02sT0B24A/bOMTgdPm\nu5/FsHL4+a03quonwJFbbyxoVfUV4HvTyhsY/KWgPV86VL+9qp6tqseBvQz6XlCq6mBVfa2Nfwjs\nZvDt94nsqwZ+1F6e0B7FhPZzRJKVwCXAx4bKE93TUUxkT0lex+Afj7cAVNVPqur7zHM/iyEcZrr1\nxooxzWVUy6vqYBs/BSxv44nrMckq4HwG/9qe2L7a6ZeHgEPAPVU10f00HwU+CPxsqDbpPRXwhSQP\ntDspwOT2tBo4DHyinfr7WJLXMM/9LIZwWJRqsF6cyI+SJTkF+Azwgap6ZnjbpPVVVc9X1ZsZfGv/\nwiTnTds+Uf0keS9wqKoeONo+k9ZT8/b25/Ru4Ook7xjeOGE9LWVwyvmmqjof+DGD00g/Nx/9LIZw\neFm33pgQTyc5C6A9H2r1iekxyQkMguFTVfXZVp74vtqy/kvAeia7n7cB70uyj8Ep2Hcl+SST3RNV\ndaA9HwL+mcFplUntaT+wv61SAe5gEBbz2s9iCIfFdOuNHcCmNt4E3DlU35jkpCSrgTXA/WOY34tK\nEgbnSXdX1UeGNk1kX0mWJTmtjU9m8PtGvsGE9gNQVddW1cqqWsXgv5UvVtX7meCekrwmyWuPjIHf\nBh5hQnuqqqeAJ5O8sZUuYvDrC+a3n3FflZ+LB/AeBp+M+SbwoXHP52XO+dPAQeCnDP6lcAXwemAn\n8BjwBeCMof0/1PrbA7x73PM/Sk9vZ7DU/U/gofZ4z6T2Bfwa8GDr5xHgL1t9IvuZob938v+fVprY\nnhh8UvHr7bHryP8DJrynNwNT7e/evwCnz3c/fkNaktRZDKeVJElzzHCQJHUMB0lSx3CQJHUMB0lS\nx3CQJHUMB0lSx3CQJHX+D1QKjRJBWOcDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48d30cac88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(lengths,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_query (InputLayer)         (None, 6)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_doc (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)         multiple              22880500                                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_42 (Dense)                 multiple              4040                                         \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional) (None, 6, 30)         17040                                        \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional) (None, 100, 30)       17040                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_43 (Dense)                 (None, 6, 50)         1550                                         \n",
      "____________________________________________________________________________________________________\n",
      "dense_44 (Dense)                 (None, 100, 50)       1550                                         \n",
      "____________________________________________________________________________________________________\n",
      "input_exact_match (InputLayer)   (None, 6, 100)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_9 (Dot)                      (None, 6, 100)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_45 (Dense)                 (None, 6, 100)        10100                                        \n",
      "____________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)               (None, 6, 100, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)               (None, 6, 100, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, 6, 100, 2)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 4, 98, 18)     342                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 4, 97, 18)     450                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, 4, 96, 18)     558                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, 4, 98, 20)     380                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, 4, 97, 20)     380                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, 4, 96, 20)     380                                          \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_25 (GlobalM (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_26 (GlobalM (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_27 (GlobalM (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_46 (Dense)                 (None, 13)            273                                          \n",
      "====================================================================================================\n",
      "Total params: 22,934,583\n",
      "Trainable params: 54,083\n",
      "Non-trainable params: 22,880,500\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TODO testing\n",
    "#doc_max_len=doc_min_len\n",
    "print('Building model...')\n",
    "\n",
    "def get_R(x):\n",
    "    a, b = x.values()\n",
    "    return K.dot(a, b)\n",
    "\n",
    "\n",
    "embeddings = word2vec_embedding_layer(embeddings_path)\n",
    "\n",
    "#embedding lookup\n",
    "# TODO: replace this with embedding with mask zero rather than padding, need to change index for encoding too, imput dim too.\n",
    "# TODO: OOV embedding\n",
    "input_query = Input(shape=(query_max_len,), dtype='int32', name='input_query')\n",
    "input_doc = Input(shape=(doc_max_len,), dtype='int32', name='input_doc')\n",
    "input_exact_match = Input(shape=(query_max_len,doc_max_len), dtype='float32', name='input_exact_match')\n",
    "input_doc = Input(shape=(doc_max_len,), dtype='int32', name='input_doc')\n",
    "embedding_query = embeddings(input_query)  # (None, 6, 100)\n",
    "embedding_doc = embeddings(input_doc)      # (None, 400, 100)\n",
    "\n",
    "#shared linear projection\n",
    "shared_lp = Dense(40,activation='linear')\n",
    "query_output = shared_lp(embedding_query) # (None, 6, 40) \n",
    "doc_output = shared_lp(embedding_doc) #(None, 400, 40) \n",
    "\n",
    "#query: bi LSTM, lp -- implementation = 0 for CPU option, 1 or 2 for GPU\n",
    "query_output = Bidirectional(LSTM(30, dropout=0.0, implementation=2, return_sequences=True, go_backwards=True,use_bias=True,unit_forget_bias=True,)\\\n",
    "                             ,merge_mode='mul'#TODO: alts are 'sum','mul','ave','concat'<--default, None\n",
    "                            )(query_output) #(None, 6, 30) unless concat (None, 6, 60)  \n",
    "query_output = Dense(50,activation='linear')(query_output) #(None, 50)\n",
    "\n",
    "#doc: bi LSTM, lp\n",
    "doc_output = Bidirectional(LSTM(30, dropout=0.0, implementation=2, return_sequences=True, go_backwards=True,use_bias=True,unit_forget_bias=True,)\\\n",
    "                             ,merge_mode='mul'#TODO: alts are 'sum','mul','ave','concat'<--default, None\n",
    "                            )(doc_output) #(None, 6, 400) unless concat (None, 6, 800)  \n",
    "doc_output = Dense(50,activation='linear')(doc_output) #(None, 50)\n",
    "\n",
    "#2d product\n",
    "#mt_input = batch_dot(query_output,doc_output,axes=None) #axes=[2,2])\n",
    "#query_output = Flatten()(query_output)\n",
    "#doc_output = Flatten()(doc_output)\n",
    "#mt_input = multiply([query_output, doc_output])\n",
    "#mt_input = dot([query_output, doc_output], axes=(0), normalize=False)  \n",
    "dot_product_output = dot([query_output, doc_output], axes=(2), normalize=True)  \n",
    "#output is (11, 6, 400), where did 50 go?\n",
    "def func_expand_dims(x):\n",
    "    return expand_dims(x, axis=-1)\n",
    "\n",
    "def expand_dims_output_shape(input_shape):\n",
    "    return (input_shape[0], input_shape[1],input_shape[2],1)\n",
    "\n",
    "mt_input_1 = Lambda(func_expand_dims, expand_dims_output_shape)(dot_product_output)\n",
    "\n",
    "#mt_input = dot([transpose(query_output), transpose(doc_output)], axes=(0), normalize=False)  \n",
    "######################################\n",
    "\n",
    "def state_layer_dot_prod(x):\n",
    "    output_list=[]\n",
    "#    output = dot([x[0], x[1]], axes=(2), normalize=False)  \n",
    "    for i in range(50):\n",
    "        print(i)\n",
    "        print(x[0][i])\n",
    "        print(x[1][i])\n",
    "        #output = multiply([transpose(x[0][i]), x[1][i]])\n",
    "        #output_list += output\n",
    "        #output = dot([x[0][i], transpose(x[1][i])])\n",
    "        #transpose(x[1][i])\n",
    "    print(output_list)\n",
    "    return output_list\n",
    "\n",
    "def state_layer_dot_prod_shape(input_shape):\n",
    "    'Merge output shape'\n",
    "    shape = list(input_shape)\n",
    "    #print(input_shape)\n",
    "    #print(shape)\n",
    "    outshape = (shape[0][0],shape[1][1],shape[0][1],shape[0][2])\n",
    "    #print(outshape)\n",
    "    return tuple(outshape)\n",
    "\n",
    "######################################\n",
    "#mt_input = Lambda(state_layer_dot_prod,output_shape=state_layer_dot_prod_shape)([transpose(query_output), transpose(doc_output)])\n",
    "#mt_input = Lambda(state_layer_dot_prod,output_shape=state_layer_dot_prod_shape)([query_output, doc_output])\n",
    "\n",
    "##TODO fix error:\n",
    "#InvalidArgumentError: Input to reshape is a tensor with 4800 values, but the requested shape requires a multiple of 120000\n",
    "#[[Node: reshape_23/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](lambda_40/dot_42/MatMul, reshape_23/Reshape/shape)]]\n",
    "#mt_input = Reshape((doc_max_len, query_max_len,50))(mt_input)\n",
    "\n",
    "#Append exact match channel\n",
    "output_exact_match = Dense(doc_max_len,activation='linear')(input_exact_match)\n",
    "mt_input_2 = Lambda(func_expand_dims, expand_dims_output_shape)(output_exact_match)\n",
    "# mt_input = concatenate([mt_input_1,mt_input_2],axis=0)\n",
    "mt_input = concatenate([mt_input_1,mt_input_2],axis=3)\n",
    "#TODO testing\n",
    "#mt_input = mt_input_1\n",
    "\n",
    "# Conv layers 1\n",
    "output1 = Conv2D(filters=18, kernel_size=(3, 3), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(mt_input)\n",
    "\n",
    "output2 = Conv2D(filters=18, kernel_size=(3, 4), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(mt_input)\n",
    "\n",
    "output3 = Conv2D(filters=18, kernel_size=(3, 5), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(mt_input)\n",
    "\n",
    "# Conv layers 2\n",
    "output1 = Conv2D(filters=20, kernel_size=(1, 1), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(output1)\n",
    "\n",
    "output2 = Conv2D(filters=20, kernel_size=(1, 1), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(output2)\n",
    "\n",
    "output3 = Conv2D(filters=20, kernel_size=(1, 1), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(output3)\n",
    "\n",
    "# Max pool layer\n",
    "output1 = GlobalMaxPooling2D(data_format='channels_last')(output1)\n",
    "output2 = GlobalMaxPooling2D(data_format='channels_last')(output2)\n",
    "output3 = GlobalMaxPooling2D(data_format='channels_last')(output3)\n",
    "\n",
    "# Merge\n",
    "output_combined = add([output1,output2,output3])\n",
    "#TODO testing\n",
    "#output_combined = output1\n",
    "\n",
    "# Final layer\n",
    "#output = Dense(1,activation='sigmoid')(output_combined)\n",
    "#categorical\n",
    "output = Dense(13, activation='softmax', kernel_initializer='glorot_uniform')(output_combined)\n",
    "\n",
    "\n",
    "# build model\n",
    "#model = Model([input_query], [query_output])\n",
    "#model = Model([input_doc], [encoded_doc])\n",
    "#model = Model([input_query,input_doc], [output1,output2,output3])\n",
    "#model = Model([input_query,input_doc], [output_combined])\n",
    "#model = Model([input_query,input_doc,input_exact_match], [query_output])\n",
    "#model = Model([input_query,input_doc], [query_output,doc_output])\n",
    "#model = Model([input_query,input_doc], [output])\n",
    "#model = Model([input_query,input_doc,input_exact_match], [mt_input])\n",
    "#model = Model([input_query,input_doc,input_exact_match], [mt_input_1,mt_input_2])\n",
    "model = Model([input_query,input_doc,input_exact_match], [output])\n",
    "#model = Model([input_query,input_doc,input_exact_match], [dot_product_output])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #TODO SSM\n",
    "# #doc_max_len=doc_min_len\n",
    "# print('Building model...')\n",
    "\n",
    "# def get_R(x):\n",
    "#     a, b = x.values()\n",
    "#     return K.dot(a, b)\n",
    "\n",
    "\n",
    "# embeddings = word2vec_embedding_layer(embeddings_path)\n",
    "\n",
    "# #embedding lookup\n",
    "# # TODO: replace this with embedding with mask zero rather than padding, need to change index for encoding too, imput dim too.\n",
    "# # TODO: OOV embedding\n",
    "# input_query = Input(shape=(query_max_len,), dtype='int32', name='input_query')\n",
    "# input_doc = Input(shape=(doc_max_len,), dtype='int32', name='input_doc')\n",
    "# input_exact_match = Input(shape=(query_max_len,doc_max_len), dtype='float32', name='input_exact_match')\n",
    "# input_doc = Input(shape=(doc_max_len,), dtype='int32', name='input_doc')\n",
    "# embedding_query = embeddings(input_query)  # (None, 6, 100)\n",
    "# embedding_doc = embeddings(input_doc)      # (None, 400, 100)\n",
    "\n",
    "# #shared linear projection\n",
    "# shared_lp = Dense(40,activation='linear')\n",
    "# query_output = shared_lp(embedding_query) # (None, 6, 40) \n",
    "# doc_output = shared_lp(embedding_doc) #(None, 400, 40) \n",
    "\n",
    "# #query: bi LSTM, lp -- implementation = 0 for CPU option, 1 or 2 for GPU\n",
    "# query_output = Bidirectional(LSTM(16, dropout=0.0, implementation=0, return_sequences=True, go_backwards=True)\\\n",
    "#                              ,merge_mode='mul'#TODO: alts are 'sum','mul','ave','concat'<--default, None\n",
    "#                             )(query_output) #(None, 6, 30) unless concat (None, 6, 60)  \n",
    "# query_output = Dense(50,activation='linear')(query_output) #(None, 50)\n",
    "\n",
    "# #doc: bi LSTM, lp\n",
    "# doc_output = Bidirectional(LSTM(64, dropout=0.0, implementation=0, return_sequences=True, go_backwards=True)\\\n",
    "#                              ,merge_mode='mul'#TODO: alts are 'sum','mul','ave','concat'<--default, None\n",
    "#                             )(doc_output) #(None, 6, 400) unless concat (None, 6, 800)  \n",
    "# doc_output = Dense(50,activation='linear')(doc_output) #(None, 50)\n",
    "\n",
    "# #2d product\n",
    "# #mt_input = batch_dot(query_output,doc_output,axes=None) #axes=[2,2])\n",
    "# #query_output = Flatten()(query_output)\n",
    "# #doc_output = Flatten()(doc_output)\n",
    "# #mt_input = multiply([query_output, doc_output])\n",
    "# #mt_input = dot([query_output, doc_output], axes=(0), normalize=False)  \n",
    "# dot_product_output = dot([query_output, doc_output], axes=(2), normalize=True)  \n",
    "# #output is (11, 6, 400), where did 50 go?\n",
    "# def func_expand_dims(x):\n",
    "#     return expand_dims(x, axis=-1)\n",
    "\n",
    "# def expand_dims_output_shape(input_shape):\n",
    "#     return (input_shape[0], input_shape[1],input_shape[2],1)\n",
    "\n",
    "# mt_input_1 = Lambda(func_expand_dims, expand_dims_output_shape)(dot_product_output)\n",
    "\n",
    "\n",
    "# # Merge\n",
    "# #output_combined = add([output1,output2,output3])\n",
    "# #TODO testing\n",
    "# output1 = GlobalMaxPooling2D(data_format='channels_last')(mt_input_1)\n",
    "# output_combined = output1\n",
    "\n",
    "\n",
    "# # Final layer\n",
    "# output = Dense(1,activation='sigmoid')(output_combined)\n",
    "# #categorical\n",
    "# #output = Dense(13, activation='softmax', kernel_initializer='glorot_uniform', use_bias=True)(output_combined)\n",
    "\n",
    "\n",
    "# # build model\n",
    "# #model = Model([input_query], [query_output])\n",
    "# #model = Model([input_doc], [encoded_doc])\n",
    "# #model = Model([input_query,input_doc], [output1,output2,output3])\n",
    "# #model = Model([input_query,input_doc], [output_combined])\n",
    "# #model = Model([input_query,input_doc,input_exact_match], [query_output])\n",
    "# #model = Model([input_query,input_doc], [query_output,doc_output])\n",
    "# #model = Model([input_query,input_doc], [output])\n",
    "# #model = Model([input_query,input_doc,input_exact_match], [mt_input])\n",
    "# #model = Model([input_query,input_doc,input_exact_match], [mt_input_1,mt_input_2])\n",
    "# model = Model([input_query,input_doc,input_exact_match], [output])\n",
    "\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # from keras.layers import Input, merge\n",
    "# # from keras.models import Model\n",
    "# # import numpy as np\n",
    "\n",
    "# # input_a = np.reshape([[1, 2, 3],[1, 2, 3],],[[1, 2, 3],[1, 2, 3]])\n",
    "# # input_b = np.reshape([4, 5, 6], (1, 1, 3))\n",
    "\n",
    "# # print(input_a)\n",
    "# # print(input_b)\n",
    "# # a = Input(shape=(1, 3))\n",
    "# # b = Input(shape=(1, 3))\n",
    "\n",
    "# # concat = merge([a, b], mode='concat', concat_axis=-1)\n",
    "# # dot = merge([a, b], mode='dot', dot_axes=2)\n",
    "# # cos = merge([a, b], mode='cos', dot_axes=2)\n",
    "\n",
    "# # model_concat = Model(input=[a, b], output=concat)\n",
    "# # model_dot = Model(input=[a, b], output=dot)\n",
    "# # model_cos = Model(input=[a, b], output=cos)\n",
    "\n",
    "# # print(model_concat.predict([input_a, input_b]))\n",
    "# # print(model_dot.predict([input_a, input_b]))\n",
    "# # print(model_cos.predict([input_a, input_b]))\n",
    "\n",
    "# from keras import backend as K\n",
    "# x_batch = K.ones(shape=(11, 6,50 ))\n",
    "# y_batch = K.ones(shape=(11, 400,50))\n",
    "# x_batch=K.batch_flatten(x_batch)\n",
    "# y_batch=K.batch_flatten(y_batch)\n",
    "# #xy_batch_dot = K.dot(transpose(y_batch),x_batch )#, axes=[0,0])\n",
    "# xy_batch_dot = K.batch_dot(x_batch,y_batch, axes=[0,0])\n",
    "# K.int_shape(xy_batch_dot)\n",
    "# # K.int_shape(x_batch)\n",
    "# # K.int_shape(y_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "#optimizer = optimizers.SGD(lr = 0.001, momentum = 0.9, decay = 0.0, nesterov = True)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
    "#model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_query_train shape: (74067, 6)\n",
      "x_doc_train shape: (74067, 100)\n",
      "y_train shape: (74067, 13)\n"
     ]
    }
   ],
   "source": [
    "x_query_train=np.array(query_word2vec_idx_list)[0:74067]\n",
    "x_doc_train=np.array(doc_word2vec_idx_list)[0:74067]#[0:len(x_query_train)]\n",
    "\n",
    "# TODO: replace this with embedding with mask zero rather than padding, need to change index for encoding too, imput dim too.\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_query_train = sequence.pad_sequences(x_query_train, maxlen=query_max_len,padding='post', truncating='post', value=0.)\n",
    "x_doc_train = sequence.pad_sequences(x_doc_train, maxlen=doc_max_len,padding='post', truncating='post', value=0.)\n",
    "# x_query_test = sequence.pad_sequences(x_query_test, maxlen=query_max_len)\n",
    "# x_doc_test = sequence.pad_sequences(x_doc_test, maxlen=doc_max_len)\n",
    "\n",
    "print('x_query_train shape:', x_query_train.shape)\n",
    "print('x_doc_train shape:', x_doc_train.shape)\n",
    "# print('x_query_test shape:', x_query_test.shape)\n",
    "# print('x_doc_test shape:', x_doc_test.shape)\n",
    "\n",
    "#TODO: y label on 0-1 scale from 1-3\n",
    "#y_train=(train_query_df['relevance'].as_matrix()-1)/3\n",
    "\n",
    "# TODO: as categorical\n",
    "y_train=to_categorical(train_query_df['relevance_int'].as_matrix(),13)\n",
    "# y_test=test_query_df['relevance_int'].as_matrix()\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(query_word2vec_idx_list,key=len)) \n",
    "len(max(x_query_train,key=len)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_doc_train[100]\n",
    "y_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exact_match_list=[]\n",
    "for i in range(x_query_train.shape[0]):\n",
    "    #print(i)\n",
    "    c1=x_query_train[i]\n",
    "    c2=x_doc_train[i]\n",
    "    #print(c1.shape[0])\n",
    "    #print(c2.shape[0])\n",
    "\n",
    "    c1_inp=np.repeat(c1,c2.shape[0],axis=0)\n",
    "    c1_inp=c1_inp.reshape((c1.shape[0],c2.shape[0]))\n",
    "    #print(c1_inp.shape)\n",
    "    #print(c1_inp)\n",
    "\n",
    "    #print(c2)\n",
    "    c2_inp=np.tile(c2,(c1.shape[0],1))\n",
    "    #print(c2_inp.shape)\n",
    "    #print(c2_inp)    \n",
    "    #print(c1_inp == c2_inp)\n",
    "    exact_match_list+=[(c1_inp == c2_inp).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exact_match_inp_train=np.array(exact_match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74067, 6, 100)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match_inp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle bracket\n",
      "simpson strong tie 12 gauge angle\n",
      "[ 882 4970 1440 2326    0    0]\n",
      "[16197   777   457 13755 15331 15855   711  4970  1440   108    70     1\n",
      "   411 13755 15331 15855   711   626  4970  1440  2065    90   388  3839\n",
      "   873   180   169   799  1483   896   584     6  2513   231    32   271\n",
      "    50  1474   622    52     8    20    54   193  1440   456  1394   433\n",
      "  3643  6746    46  4970   108  2513  1027 16894  3113   622    52 23494\n",
      " 40170  2276   109   510 40171  1440   108     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "[[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(train_query_df['search_term'][0])\n",
    "print(product_df['product_title'][0])\n",
    "print(x_query_train[i])\n",
    "print(x_doc_train[i])\n",
    "print(exact_match_inp_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 59253 samples, validate on 14814 samples\n",
      "Epoch 1/10\n",
      "99s - loss: 0.0626 - acc: 0.2709 - val_loss: 0.0653 - val_acc: 0.1844\n",
      "Epoch 2/10\n",
      "92s - loss: 0.0605 - acc: 0.3117 - val_loss: 0.0644 - val_acc: 0.2054\n",
      "Epoch 3/10\n",
      "90s - loss: 0.0600 - acc: 0.3202 - val_loss: 0.0649 - val_acc: 0.2037\n",
      "Epoch 4/10\n",
      "91s - loss: 0.0594 - acc: 0.3264 - val_loss: 0.0654 - val_acc: 0.1952\n",
      "Epoch 5/10\n",
      "96s - loss: 0.0590 - acc: 0.3353 - val_loss: 0.0642 - val_acc: 0.2147\n",
      "Epoch 6/10\n",
      "117s - loss: 0.0586 - acc: 0.3390 - val_loss: 0.0648 - val_acc: 0.2191\n",
      "Epoch 7/10\n",
      "104s - loss: 0.0582 - acc: 0.3435 - val_loss: 0.0638 - val_acc: 0.2338\n",
      "Epoch 8/10\n",
      "95s - loss: 0.0579 - acc: 0.3505 - val_loss: 0.0645 - val_acc: 0.2271\n",
      "Epoch 9/10\n",
      "110s - loss: 0.0575 - acc: 0.3559 - val_loss: 0.0640 - val_acc: 0.2332\n",
      "Epoch 10/10\n",
      "135s - loss: 0.0572 - acc: 0.3641 - val_loss: 0.0642 - val_acc: 0.2288\n"
     ]
    }
   ],
   "source": [
    "batch_size=300#2 #200\n",
    "print('Train...')\n",
    "hist=model.fit([x_query_train,x_doc_train,exact_match_inp_train], [y_train],\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          verbose=2,\n",
    "          #validation_data=[x_test, y_test])\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAFNCAYAAABCCkHgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBEREREREQEUEEVERERERCTg/wMeTffl4qBrPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f481a404fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['acc']); plt.plot(hist.history['val_acc']);\n",
    "plt.title('model accuracy'); plt.ylabel('accuracy');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss']); plt.plot(hist.history['val_loss']);\n",
    "plt.title('model loss'); plt.ylabel('loss');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=200 #200\n",
    "prediction=model.predict([x_query_train,x_doc_train,exact_match_inp_train],\n",
    "          batch_size=batch_size,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74067, 13)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.49889530e-02,   3.30214709e-04,   2.22766008e-02,\n",
       "         9.46527289e-05,   4.52328771e-02,   7.59399671e-04,\n",
       "         8.27541351e-02,   1.66393176e-04,   1.50801823e-01,\n",
       "         2.23548905e-05,   2.54998535e-01,   3.12221207e-04,\n",
       "         4.17261809e-01], dtype=float32)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred2relevance(prediction):\n",
    "    orig_labels = [ 1.  ,  1.25 , 1.33 , 1.5 ,  1.67,  1.75,  2. ,   2.25 , 2.33  ,2.5 ,  2.67  ,2.75 ,3.  ]\n",
    "    new_labels= [ 0 , 1 , 2 , 3 , 4 , 5,  6 , 7 , 8,  9, 10 ,11, 12]\n",
    "    orig_labels_prediction=[]\n",
    "    for preds in prediction:\n",
    "        #print(preds)\n",
    "        max_idx=np.argmax(preds)\n",
    "        orig_labels_prediction+=[orig_labels[max_idx]]\n",
    "    return np.array(orig_labels_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig_labels_prediction =  pred2relevance(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_labels_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE = mean_squared_error(train_query_df['relevance'].as_matrix(), orig_labels_prediction)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59375040995940442"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# print(\"Predict\")\n",
    "word_a = 'wood'#raw_input('First word: ')\n",
    "if word_a not in word2idx:\n",
    "    print('\"%s\" is not in the index' % word_a)\n",
    "word_b = 'fan'#raw_input('Second word: ')\n",
    "if word_b not in word2idx:\n",
    "    print('\"%s\" is not in the index' % word_b)\n",
    "output = model.predict([np.asarray([word2idx[word_a]]), np.asarray([word2idx[word_b]])])\n",
    "print('%f' % output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df=test_private_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from search string\n"
     ]
    }
   ],
   "source": [
    "test_query_sentences = []\n",
    "\n",
    "print(\"Parsing sentences from search string\")\n",
    "for query in test_df[\"search_term\"]:\n",
    "    test_query_sentences += [doc_to_wordlist(query, remove_stopwords=True)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78419"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_query_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78419\n"
     ]
    }
   ],
   "source": [
    "test_query_word2vec_idx_list = query_sent2idx(test_query_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78419\n"
     ]
    }
   ],
   "source": [
    "test_joined_df=test_df.join(product_df.set_index('product_uid'), on='product_uid')\n",
    "\n",
    "test_joined_doc_sentences=[]\n",
    "for doc in test_joined_df['content']:\n",
    "    test_joined_doc_sentences += [doc_to_wordlist(doc, remove_stopwords=True)]\n",
    "    \n",
    "test_doc_word2vec_idx_list = query_sent2idx(test_joined_doc_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_query_test shape: (78419, 6)\n",
      "x_doc_test shape: (78419, 100)\n"
     ]
    }
   ],
   "source": [
    "x_query_test=np.array(test_query_word2vec_idx_list)[0:78419]\n",
    "x_doc_test=np.array(test_doc_word2vec_idx_list)[0:78419]\n",
    "\n",
    "# TODO: replace this with embedding with mask zero rather than padding, need to change index for encoding too, imput dim too.\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_query_test = sequence.pad_sequences(x_query_test, maxlen=query_max_len,padding='post', truncating='post', value=0.)\n",
    "x_doc_test = sequence.pad_sequences(x_doc_test, maxlen=doc_max_len,padding='post', truncating='post', value=0.)\n",
    "# x_query_test = sequence.pad_sequences(x_query_test, maxlen=query_max_len)\n",
    "# x_doc_test = sequence.pad_sequences(x_doc_test, maxlen=doc_max_len)\n",
    "\n",
    "print('x_query_test shape:', x_query_test.shape)\n",
    "print('x_doc_test shape:', x_doc_test.shape)\n",
    "\n",
    "#TODO: y label on 0-1 scale from 1-3\n",
    "#y_train=(train_query_df['relevance'].as_matrix()-1)/3\n",
    "\n",
    "# TODO: as categorical\n",
    "#y_test=to_categorical(train_query_df['relevance_int'].as_matrix(),13)\n",
    "# y_test=test_query_df['relevance_int'].as_matrix()\n",
    "#print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78419, 6, 100)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match_list_test=[]\n",
    "for i in range(x_query_test.shape[0]):\n",
    "    #print(i)\n",
    "    c1=x_query_test[i]\n",
    "    c2=x_doc_test[i]\n",
    "    #print(c1.shape[0])\n",
    "    #print(c2.shape[0])\n",
    "\n",
    "    c1_inp=np.repeat(c1,c2.shape[0],axis=0)\n",
    "    c1_inp=c1_inp.reshape((c1.shape[0],c2.shape[0]))\n",
    "    #print(c1_inp.shape)\n",
    "    #print(c1_inp)\n",
    "\n",
    "    #print(c2)\n",
    "    c2_inp=np.tile(c2,(c1.shape[0],1))\n",
    "    #print(c2_inp.shape)\n",
    "    #print(c2_inp)    \n",
    "    #print(c1_inp == c2_inp)\n",
    "    exact_match_list_test+=[(c1_inp == c2_inp).astype(int)]\n",
    "\n",
    "exact_match_inp_test=np.array(exact_match_list_test)\n",
    "exact_match_inp_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 degree bracket\n",
      "[1722 5130 1549    0    0    0]\n",
      "[ 1722   369  1045   272   572  2838   144  1369  1941    77    36  1164\n",
      "   813   981  1722   369  1045    58   117   158  2838  1006   389  5229\n",
      "    59     6    81  1655   520  1459   562   514  4694 12149   433   365\n",
      "    28   520   406  2411     2  9881   625   273  1093    36   264   361\n",
      "   310    46  1191   263   413  1064   483   722  1006  1228    11   794\n",
      " 34116  2010  2666   323  1241 34117   401  1369  4930   813 37211     1\n",
      "     1    29   272  5502   264   310  6226   673   649     1   369   394\n",
      "  3282   248     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(test_query_df['search_term'][0])\n",
    "print(x_query_test[0])\n",
    "print(x_doc_test[0])\n",
    "print(exact_match_inp_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=300 #200\n",
    "test_prediction=model.predict([x_query_test,x_doc_test,exact_match_inp_test],\n",
    "          batch_size=batch_size,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78419, 13)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.42920481e-02,   4.53530311e-06,   3.65434587e-02,\n",
       "         3.24295579e-05,   1.39181674e-01,   3.93238530e-04,\n",
       "         4.35907900e-01,   4.15777176e-05,   2.15909958e-01,\n",
       "         4.11668907e-06,   1.27853900e-01,   1.73360822e-04,\n",
       "         1.96618717e-02], dtype=float32)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_orig_labels_prediction =  pred2relevance(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_orig_labels_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63874448062914368"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_RMSE = mean_squared_error(test_df['relevance'].as_matrix(), test_orig_labels_prediction)**0.5\n",
    "test_RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
