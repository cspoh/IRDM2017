{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match tensor v3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import merge, Dense, Input,Dropout, Embedding, LSTM, Bidirectional, Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.merge import dot, multiply, add, concatenate\n",
    "from keras.layers import Merge\n",
    "from keras.layers.core import Lambda,Reshape, Flatten\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.backend import transpose,batch_dot,expand_dims\n",
    "from keras import optimizers\n",
    "from HomeDepotCSVReader import HomeDepotReader\n",
    "import Utilities\n",
    "from DataPreprocessing import DataPreprocessing\n",
    "from Feature_Word2Vec import Feature_Word2Vec\n",
    "from AutomaticQueryExpansion import Word2VecQueryExpansion\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from FeatureEngineering import HomeDepotFeature\n",
    "from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_filename = '../data/train_play.csv'\n",
    "# test_filename = '../data/test_play.csv'\n",
    "# attribute_filename = '../data/attributes_play.csv'\n",
    "# description_filename = '../data/product_descriptions_play.csv'\n",
    "# word2vec_model_path='model/word2vec_play.model'\n",
    "# vocab_path='model/word2vec_play_vocab.json'\n",
    "# embeddings_path='model/embeddings_play.npz'\n",
    "\n",
    "train_filename = '../data/train.csv'\n",
    "test_filename = '../data/test.csv'\n",
    "soln_filename = '../data/solution.csv'\n",
    "attribute_filename = '../data/attributes.csv'\n",
    "description_filename = '../data/product_descriptions.csv'\n",
    "word2vec_model_path='model/word2vec.model'\n",
    "vocab_path='model/word2vec_vocab.json'\n",
    "embeddings_path='model/embeddings.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========Tranforming labels...\n",
      "showing current values\n",
      "trainDF: ['id', 'product_uid', 'search_term', 'relevance']\n",
      "trainDF:    id  product_uid    search_term  relevance\n",
      "0   2       100001  angle bracket        3.0\n",
      "self.mergedLabelDF: ['relevance'] \n",
      " <class 'pandas.core.frame.DataFrame'> (74067, 1)    relevance\n",
      "0        3.0\n",
      "Old unique Labels: [ 1.    1.25  1.33  1.5   1.67  1.75  2.    2.25  2.33  2.5   2.67  2.75\n",
      "  3.  ]\n",
      "newLabels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "Creating new column for training:  relevance_int\n",
      "===========Transform labels completed\n",
      "train_query_df: ['id', 'product_uid', 'search_term', 'relevance', 'relevance_int', 'product_idx']\n",
      "product_df: ['product_title', 'product_uid', 'product_description']\n",
      "attribute_df: ['product_uid', 'name', 'value']\n",
      "test_query_df: ['id', 'product_uid', 'search_term']\n"
     ]
    }
   ],
   "source": [
    "reader = HomeDepotReader()\n",
    "\n",
    "train_query_df, product_df, attribute_df, test_query_df = reader.getQueryProductAttributeDataFrame(train_filename,\n",
    "                                              test_filename,\n",
    "                                              attribute_filename,\n",
    "                                              description_filename)\n",
    "print(\"train_query_df:\",list(train_query_df))\n",
    "print(\"product_df:\", list(product_df))\n",
    "print(\"attribute_df:\", list(attribute_df))\n",
    "print(\"test_query_df:\", list(test_query_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform attribute into doc\n",
    "dp = DataPreprocessing()\n",
    "attribute_doc_df = dp.getAttributeDoc(attribute_df)\n",
    "#attribute_doc_df\n",
    "product_df=product_df.join(attribute_doc_df.set_index('product_uid'), on = 'product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### test data\n",
    "soln_df = pd.read_csv(soln_filename, delimiter=',', low_memory=False, encoding=\"ISO-8859-1\")\n",
    "test_private_df = dp.getGoldTestSet(test_query_df, soln_df, testsetoption='Private')#,savepath='../data/test_private_gold.csv')\n",
    "test_public_df = dp.getGoldTestSet(test_query_df, soln_df, testsetoption='Public')# savepath='../data/test_public_gold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spell correction\n",
      "Performing non-ascii removal\n",
      "Non-ascii clean on search_term took: 0.01 minutes\n",
      "Non-ascii clean on product_title took: 0.03 minutes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74067 entries, 0 to 74066\n",
      "Data columns (total 6 columns):\n",
      "id               74067 non-null int64\n",
      "product_uid      74067 non-null int64\n",
      "search_term      74067 non-null object\n",
      "relevance        74067 non-null float64\n",
      "relevance_int    74067 non-null int64\n",
      "product_idx      74067 non-null object\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 3.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_query_df = HomeDepotFeature().getFeature(train_query_df, product_df, attribute_df, test_private_df,\n",
    "                        features=\"spelling,nonascii\")\n",
    "#,stopwords,stemming\n",
    "#\"spelling,nonascii\" no diff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spell correction\n",
      "Performing non-ascii removal\n",
      "Non-ascii clean on search_term took: 0.01 minutes\n",
      "Non-ascii clean on product_title took: 0.03 minutes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78419 entries, 2 to 147405\n",
      "Data columns (total 4 columns):\n",
      "id             78419 non-null int64\n",
      "product_uid    78419 non-null int64\n",
      "search_term    78419 non-null object\n",
      "relevance      78419 non-null float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_private_df = HomeDepotFeature().getFeature(test_private_df, product_df, attribute_df, test_private_df,\n",
    "                        features=\"spelling,nonascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spell correction\n",
      "Performing non-ascii removal\n",
      "Non-ascii clean on search_term took: 0.0 minutes\n",
      "Non-ascii clean on product_title took: 0.03 minutes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33648 entries, 1 to 147404\n",
      "Data columns (total 4 columns):\n",
      "id             33648 non-null int64\n",
      "product_uid    33648 non-null int64\n",
      "search_term    33648 non-null object\n",
      "relevance      33648 non-null float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_public_df = HomeDepotFeature().getFeature(test_public_df, product_df, attribute_df, test_public_df,\n",
    "                        features=\"spelling,nonascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# product_df['content'] = train_query_df['search_term'].map(str) + \" \" + \\\n",
    "#                         product_df['product_title'].map(str) + \" \" + \\\n",
    "#                         product_df['product_description'].map(str) + \" \" + \\\n",
    "#                         product_df['attr_json'].map(str)\n",
    "\n",
    "product_df['content'] = product_df['product_title'].map(str) + \" \" + \\\n",
    "                        product_df['product_description'].map(str) \n",
    "\n",
    "# ## no attribute\n",
    "# product_df['content'] = product_df['product_title'].map(str) + \" \" + \\\n",
    "#                         product_df['product_description'].map(str) \n",
    "        \n",
    "#product_df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33648"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_public_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors\n",
    "def doc_to_wordlist( doc, vocab=['<PAD>', '<OOV>'], remove_stopwords=False, remove_non_letters=False, remove_non_letters_numbers=True):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    #review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    if remove_non_letters:\n",
    "        doc = re.sub(\"[^a-zA-Z]\",\" \", doc)\n",
    "    # 2a. remove non-letters, numbers\n",
    "    if remove_non_letters_numbers:\n",
    "        doc = re.sub(\"[^a-zA-Z0-9]\",\" \", doc)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = doc.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        #words = [w for w in words if not w in stops]\n",
    "        new_words = []\n",
    "        for w in words:\n",
    "            if not w in stops:\n",
    "                new_words.append(w)\n",
    "                #if w not in vocab: #TODO: temp removal, too slow\n",
    "                #    vocab.append(w)\n",
    "    \n",
    "    # 5. Return a list of words\n",
    "    return new_words,vocab\n",
    "\n",
    "# words,vocab=doc_to_wordlist(product_df['content'][0],remove_stopwords=True, remove_non_letters=False, remove_non_letters_numbers=True)\n",
    "# print(len(words),len(vocab))\n",
    "# print(vocab)\n",
    "# words,vocab=doc_to_wordlist(product_df['content'][0],remove_stopwords=False, remove_non_letters=False, remove_non_letters_numbers=True)\n",
    "# print(len(words),len(vocab))\n",
    "# print(vocab)\n",
    "# product_df['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "# nltk.download()   \n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### tokenisation\n",
    "class alt_tokenizer():\n",
    "    def alt_tokenize(sentence):\n",
    "        token = re.compile(\"[\\w]+(?=n't)|n't|\\'s|\\'m|\\'ll|[\\w]+|[.?!;,\\-\\(\\)—\\:'\\\"]\")\n",
    "        return token.findall(sentence)\n",
    "\n",
    "#load alt tokenizer\n",
    "my_alt_tokenizer = alt_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to split a doc into parsed sentences\n",
    "def doc_to_sentences( doc, tokenizer, vocab=None, remove_stopwords=False, remove_non_letters=False, remove_non_letters_numbers=True ):\n",
    "    if vocab is None:\n",
    "        vocab = ['<PAD>', '<OOV>']\n",
    "    \n",
    "    # Function to split a doc into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(doc.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            (words,vocab) = doc_to_wordlist( raw_sentence, vocab, remove_stopwords )\n",
    "            sentences.append(words)\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences,vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pc600 pelican premium 10 gpm whole house carbon water filter system for homes with 1 3 bathrooms is a deluxe high capacity virtually maintenance free system that is easily installed in any home and has a 600 000 5 year capacity only the top rated valves and tanks are used in manufacturing each pelican system backed by an industry leading limited life time parts warranty imagine spring like water through every faucet of your home drink bathe and shower in sparkling clean water with no more dry itchy skin or unpleasant odors from chemicals the large diameter of the tank holds a significant amount of water filtration carbon media increasing the overall performance and life span and the replacement cost is a fraction of the cost of similar items when it comes time to replace the filter all you have to do is replace the media inside the tank with no plumbing required and no need to replace the entire tank wrapped in premium stainless steel to ensure long life durability and unsurpassed quality pelican carbon series filter features preloaded design that makes it ready to install minimizes steps and saves time minimal filter media change with the sediment pre filter every six to nine months tank 1 media every five years or 1 000 000 gallons tank 2 media is life time media that needs no replacement includes sediment pre filter system with mounting hardware bacterial static media inhibits bacterial growth energy efficient does not waste water and requires no electricity\n",
      "pelican water 10 gpm whole house carbon water filter system for homes with 1 3 bathrooms the pc600 pelican premium 10 gpm whole house carbon water filter system for homes with 1 3 bathrooms is a deluxe high capacity virtually maintenance free system that is easily installed in any home and has a 600 000 5 year capacity only the top rated valves and tanks are used in manufacturing each pelican system backed by an industry leading limited life time parts warranty imagine spring like water through every faucet of your home drink bathe and shower in sparkling clean water with no more dry itchy skin or unpleasant odors from chemicals the large diameter of the tank holds a significant amount of water filtration carbon media increasing the overall performance and life span and the replacement cost is a fraction of the cost of similar items when it comes time to replace the filter all you have to do is replace the media inside the tank with no plumbing required and no need to replace the entire tank wrapped in premium stainless steel to ensure long life durability and unsurpassed quality pelican carbon series filter features preloaded design that makes it ready to install minimizes steps and saves time minimal filter media change with the sediment pre filter every six to nine months tank 1 media every five years or 1 000 000 gallons tank 2 media is life time media that needs no replacement includes sediment pre filter system with mounting hardware bacterial static media inhibits bacterial growth energy efficient does not waste water and requires no electricity\n",
      "186\n",
      "2\n",
      "['<PAD>', '<OOV>']\n"
     ]
    }
   ],
   "source": [
    "print(product_df['product_description'][100])\n",
    "print(product_df['content'][100])\n",
    "vocab=['<PAD>', '<OOV>']\n",
    "words,vocab=doc_to_wordlist(product_df['content'][100],remove_stopwords=True, \\\n",
    "                            remove_non_letters=False, remove_non_letters_numbers=True)\n",
    "print(len(words))\n",
    "#print(len(doc_to_wordlist(product_df['content'][0],remove_stopwords=False)))\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "product_df['content'][100]\n",
    "vocab=None\n",
    "sentences,vocab = doc_to_sentences(product_df['content'][100],tokenizer,remove_stopwords=True, \\\n",
    "                            remove_non_letters=False, remove_non_letters_numbers=True)\n",
    "print(len(sentences))\n",
    "print(len(vocab))\n",
    "# print(len(doc_to_sentences(product_df['content'][0],tokenizer,remove_stopwords=True)))\n",
    "# print(len(doc_to_sentences(product_df['content'][0],tokenizer,remove_stopwords=False)))\n",
    "# product_df['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from search string\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "query_sentences = []\n",
    "doc_sentences = []\n",
    "vocab=['<PAD>', '<OOV>']\n",
    "print(\"Parsing sentences from search string\")\n",
    "for query in train_query_df[\"search_term\"]:\n",
    "    words,vocab=doc_to_wordlist(query,vocab, remove_stopwords=True, remove_non_letters=False, remove_non_letters_numbers=True)\n",
    "    query_sentences += [words]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74067\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(query_sentences))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from unlabeled set\n"
     ]
    }
   ],
   "source": [
    "print(\"Parsing sentences from unlabeled set\")\n",
    "for doc in product_df['content']:\n",
    "    words,vocab=doc_to_wordlist(doc,vocab, remove_stopwords=True,remove_non_letters=False, remove_non_letters_numbers=True)\n",
    "    doc_sentences += [words]\n",
    "\n",
    "sentences = query_sentences+doc_sentences   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198495\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-04 17:44:42,913 : INFO : collecting all words and their counts\n",
      "2017-04-04 17:44:42,926 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-04 17:44:42,942 : INFO : PROGRESS: at sentence #10000, processed 29172 words, keeping 3572 word types\n",
      "2017-04-04 17:44:42,956 : INFO : PROGRESS: at sentence #20000, processed 59500 words, keeping 4877 word types\n",
      "2017-04-04 17:44:42,971 : INFO : PROGRESS: at sentence #30000, processed 89924 words, keeping 5430 word types\n",
      "2017-04-04 17:44:42,984 : INFO : PROGRESS: at sentence #40000, processed 119667 words, keeping 5752 word types\n",
      "2017-04-04 17:44:42,998 : INFO : PROGRESS: at sentence #50000, processed 149568 words, keeping 6001 word types\n",
      "2017-04-04 17:44:43,012 : INFO : PROGRESS: at sentence #60000, processed 183701 words, keeping 6510 word types\n",
      "2017-04-04 17:44:43,029 : INFO : PROGRESS: at sentence #70000, processed 220154 words, keeping 6767 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-04 17:44:43,194 : INFO : PROGRESS: at sentence #80000, processed 932103 words, keeping 25318 word types\n",
      "2017-04-04 17:44:43,437 : INFO : PROGRESS: at sentence #90000, processed 2064512 words, keeping 38929 word types\n",
      "2017-04-04 17:44:43,684 : INFO : PROGRESS: at sentence #100000, processed 3187550 words, keeping 48854 word types\n",
      "2017-04-04 17:44:43,934 : INFO : PROGRESS: at sentence #110000, processed 4289312 words, keeping 56824 word types\n",
      "2017-04-04 17:44:44,179 : INFO : PROGRESS: at sentence #120000, processed 5411786 words, keeping 64406 word types\n",
      "2017-04-04 17:44:44,461 : INFO : PROGRESS: at sentence #130000, processed 6515745 words, keeping 70725 word types\n",
      "2017-04-04 17:44:44,768 : INFO : PROGRESS: at sentence #140000, processed 7592124 words, keeping 77066 word types\n",
      "2017-04-04 17:44:45,058 : INFO : PROGRESS: at sentence #150000, processed 8675235 words, keeping 82516 word types\n",
      "2017-04-04 17:44:45,330 : INFO : PROGRESS: at sentence #160000, processed 9753858 words, keeping 87891 word types\n",
      "2017-04-04 17:44:45,574 : INFO : PROGRESS: at sentence #170000, processed 10857383 words, keeping 92619 word types\n",
      "2017-04-04 17:44:45,821 : INFO : PROGRESS: at sentence #180000, processed 11953951 words, keeping 96698 word types\n",
      "2017-04-04 17:44:46,059 : INFO : PROGRESS: at sentence #190000, processed 13018244 words, keeping 101095 word types\n",
      "2017-04-04 17:44:46,260 : INFO : collected 104590 word types from a corpus of 13915580 raw words and 198495 sentences\n",
      "2017-04-04 17:44:46,261 : INFO : Loading a fresh vocabulary\n",
      "2017-04-04 17:44:46,908 : INFO : min_count=1 retains 104590 unique words (100% of original 104590, drops 0)\n",
      "2017-04-04 17:44:46,909 : INFO : min_count=1 leaves 13915580 word corpus (100% of original 13915580, drops 0)\n",
      "2017-04-04 17:44:47,399 : INFO : deleting the raw counts dictionary of 104590 items\n",
      "2017-04-04 17:44:47,403 : INFO : sample=0 downsamples 0 most-common words\n",
      "2017-04-04 17:44:47,404 : INFO : downsampling leaves estimated 13915580 word corpus (100.0% of prior 13915580)\n",
      "2017-04-04 17:44:47,405 : INFO : estimated required memory for 104590 words and 100 dimensions: 135967000 bytes\n",
      "2017-04-04 17:44:47,826 : INFO : resetting layer weights\n",
      "2017-04-04 17:44:49,825 : INFO : training model with 4 workers on 104590 vocabulary and 100 features, using sg=0 hs=0 sample=0 negative=5 window=10\n",
      "2017-04-04 17:44:49,826 : INFO : expecting 198495 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-04 17:44:50,868 : INFO : PROGRESS: at 7.74% examples, 548292 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:44:51,899 : INFO : PROGRESS: at 8.26% examples, 563079 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:44:52,919 : INFO : PROGRESS: at 8.64% examples, 512017 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:44:53,931 : INFO : PROGRESS: at 9.05% examples, 499472 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-04 17:44:54,952 : INFO : PROGRESS: at 9.56% examples, 510413 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:44:55,962 : INFO : PROGRESS: at 10.10% examples, 523611 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:44:57,008 : INFO : PROGRESS: at 10.63% examples, 528941 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:44:58,037 : INFO : PROGRESS: at 11.17% examples, 533961 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:44:59,055 : INFO : PROGRESS: at 11.70% examples, 539693 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:00,057 : INFO : PROGRESS: at 12.25% examples, 546068 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:01,086 : INFO : PROGRESS: at 12.76% examples, 546392 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-04 17:45:02,107 : INFO : PROGRESS: at 13.27% examples, 545492 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:45:03,124 : INFO : PROGRESS: at 13.77% examples, 544104 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:04,128 : INFO : PROGRESS: at 14.33% examples, 547596 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:05,142 : INFO : PROGRESS: at 14.90% examples, 551558 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:06,170 : INFO : PROGRESS: at 15.47% examples, 553946 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:07,176 : INFO : PROGRESS: at 16.04% examples, 557327 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:08,192 : INFO : PROGRESS: at 16.47% examples, 552463 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-04 17:45:09,217 : INFO : PROGRESS: at 16.90% examples, 547362 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:10,239 : INFO : PROGRESS: at 17.37% examples, 545258 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-04 17:45:11,241 : INFO : PROGRESS: at 17.87% examples, 544782 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:12,271 : INFO : PROGRESS: at 18.40% examples, 545035 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:13,281 : INFO : PROGRESS: at 18.91% examples, 544851 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:14,289 : INFO : PROGRESS: at 19.47% examples, 546365 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:15,292 : INFO : PROGRESS: at 21.79% examples, 548659 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:16,301 : INFO : PROGRESS: at 27.86% examples, 552523 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:17,326 : INFO : PROGRESS: at 28.40% examples, 553956 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:18,331 : INFO : PROGRESS: at 28.94% examples, 555676 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:19,338 : INFO : PROGRESS: at 29.51% examples, 558267 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:20,341 : INFO : PROGRESS: at 30.04% examples, 559454 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:21,350 : INFO : PROGRESS: at 30.60% examples, 560778 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:22,359 : INFO : PROGRESS: at 31.15% examples, 561986 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:23,381 : INFO : PROGRESS: at 31.70% examples, 563212 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:45:24,381 : INFO : PROGRESS: at 32.24% examples, 564160 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:45:25,392 : INFO : PROGRESS: at 32.80% examples, 565446 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:26,411 : INFO : PROGRESS: at 33.37% examples, 566273 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:27,415 : INFO : PROGRESS: at 33.94% examples, 567511 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:28,438 : INFO : PROGRESS: at 34.51% examples, 568182 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:29,459 : INFO : PROGRESS: at 35.10% examples, 569573 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:30,467 : INFO : PROGRESS: at 35.64% examples, 569849 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:45:31,477 : INFO : PROGRESS: at 36.19% examples, 570112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:32,480 : INFO : PROGRESS: at 36.72% examples, 570431 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:33,493 : INFO : PROGRESS: at 37.27% examples, 570841 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:34,499 : INFO : PROGRESS: at 37.79% examples, 570652 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:35,501 : INFO : PROGRESS: at 38.38% examples, 572071 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:36,507 : INFO : PROGRESS: at 38.99% examples, 573578 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:37,533 : INFO : PROGRESS: at 39.56% examples, 573953 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:38,533 : INFO : PROGRESS: at 46.02% examples, 575237 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:39,534 : INFO : PROGRESS: at 47.90% examples, 575029 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:40,549 : INFO : PROGRESS: at 48.39% examples, 574486 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:45:41,564 : INFO : PROGRESS: at 48.81% examples, 572235 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:42,571 : INFO : PROGRESS: at 49.27% examples, 571111 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:43,607 : INFO : PROGRESS: at 49.78% examples, 570820 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:44,650 : INFO : PROGRESS: at 50.21% examples, 568473 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:45,657 : INFO : PROGRESS: at 50.68% examples, 567475 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:46,676 : INFO : PROGRESS: at 51.29% examples, 569007 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:47,704 : INFO : PROGRESS: at 51.84% examples, 569530 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:48,745 : INFO : PROGRESS: at 52.33% examples, 568735 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:49,766 : INFO : PROGRESS: at 52.92% examples, 569830 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:50,768 : INFO : PROGRESS: at 53.51% examples, 570897 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:51,781 : INFO : PROGRESS: at 54.11% examples, 571975 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:45:52,790 : INFO : PROGRESS: at 54.73% examples, 573224 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:53,795 : INFO : PROGRESS: at 55.30% examples, 573837 words/s, in_qsize 8, out_qsize 1\n",
      "2017-04-04 17:45:54,795 : INFO : PROGRESS: at 55.88% examples, 574633 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:55,813 : INFO : PROGRESS: at 56.44% examples, 574952 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:56,824 : INFO : PROGRESS: at 56.99% examples, 575313 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:57,824 : INFO : PROGRESS: at 57.55% examples, 575760 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:58,829 : INFO : PROGRESS: at 58.14% examples, 576731 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:45:59,838 : INFO : PROGRESS: at 58.74% examples, 577511 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:00,854 : INFO : PROGRESS: at 59.36% examples, 578338 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:01,867 : INFO : PROGRESS: at 59.97% examples, 579026 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:02,870 : INFO : PROGRESS: at 67.84% examples, 580880 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:03,872 : INFO : PROGRESS: at 68.40% examples, 581598 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:04,880 : INFO : PROGRESS: at 68.97% examples, 582394 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:05,882 : INFO : PROGRESS: at 69.54% examples, 583080 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:06,888 : INFO : PROGRESS: at 70.12% examples, 583844 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:07,891 : INFO : PROGRESS: at 70.71% examples, 584488 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:08,904 : INFO : PROGRESS: at 71.30% examples, 585166 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:09,906 : INFO : PROGRESS: at 71.88% examples, 585898 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:10,918 : INFO : PROGRESS: at 72.46% examples, 586670 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:11,929 : INFO : PROGRESS: at 73.05% examples, 587314 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:12,938 : INFO : PROGRESS: at 73.65% examples, 587837 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:13,953 : INFO : PROGRESS: at 74.26% examples, 588527 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:14,960 : INFO : PROGRESS: at 74.86% examples, 589038 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:15,968 : INFO : PROGRESS: at 75.46% examples, 589629 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:16,980 : INFO : PROGRESS: at 76.06% examples, 590197 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:17,989 : INFO : PROGRESS: at 76.64% examples, 590651 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:19,016 : INFO : PROGRESS: at 77.23% examples, 591083 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:20,033 : INFO : PROGRESS: at 77.83% examples, 591684 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:21,039 : INFO : PROGRESS: at 78.43% examples, 592241 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:22,052 : INFO : PROGRESS: at 79.05% examples, 592743 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:23,057 : INFO : PROGRESS: at 79.66% examples, 593283 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:24,058 : INFO : PROGRESS: at 87.55% examples, 594367 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:25,062 : INFO : PROGRESS: at 88.04% examples, 594037 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:26,070 : INFO : PROGRESS: at 88.61% examples, 594520 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:27,074 : INFO : PROGRESS: at 89.19% examples, 595025 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:28,094 : INFO : PROGRESS: at 89.76% examples, 595318 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:29,111 : INFO : PROGRESS: at 90.36% examples, 595827 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:30,116 : INFO : PROGRESS: at 90.93% examples, 596187 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:31,134 : INFO : PROGRESS: at 91.51% examples, 596468 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:32,160 : INFO : PROGRESS: at 92.09% examples, 596895 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:33,164 : INFO : PROGRESS: at 92.66% examples, 597153 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:34,174 : INFO : PROGRESS: at 93.27% examples, 597665 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:35,183 : INFO : PROGRESS: at 93.85% examples, 597870 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:36,191 : INFO : PROGRESS: at 94.45% examples, 598182 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:37,200 : INFO : PROGRESS: at 95.04% examples, 598484 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:46:38,204 : INFO : PROGRESS: at 95.61% examples, 598520 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:39,222 : INFO : PROGRESS: at 96.19% examples, 598764 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:40,249 : INFO : PROGRESS: at 96.79% examples, 599125 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:41,251 : INFO : PROGRESS: at 97.37% examples, 599443 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:42,256 : INFO : PROGRESS: at 97.96% examples, 599737 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:43,261 : INFO : PROGRESS: at 98.55% examples, 600037 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:44,268 : INFO : PROGRESS: at 99.05% examples, 599270 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-04 17:46:45,281 : INFO : PROGRESS: at 99.55% examples, 598575 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-04 17:46:46,289 : INFO : PROGRESS: at 99.97% examples, 597228 words/s, in_qsize 3, out_qsize 1\n",
      "2017-04-04 17:46:46,292 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-04 17:46:46,293 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-04 17:46:46,296 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-04 17:46:46,314 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-04 17:46:46,315 : INFO : training on 69577900 raw words (69577900 effective words) took 116.5s, 597328 effective words/s\n",
      "2017-04-04 17:46:46,316 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-04-04 17:46:47,520 : INFO : saving Word2Vec object under model/word2vec.model, separately None\n",
      "2017-04-04 17:46:47,521 : INFO : not storing attribute syn0norm\n",
      "2017-04-04 17:46:47,522 : INFO : not storing attribute cum_table\n",
      "2017-04-04 17:46:48,574 : INFO : saved model/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 100#50#300    # Word vector dimensionality                      \n",
    "min_word_count = 1#5#40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 0 #1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model...\")\n",
    "word2vec_model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "word2vec_model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "#model_name = \"300features_40minwords_10context\"\n",
    "word2vec_model.save(word2vec_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104590\n"
     ]
    }
   ],
   "source": [
    "print(len(word2vec_model.wv.vocab))\n",
    "#word2vec_model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hardwood', 0.6149548888206482), ('hardwoods', 0.5928762555122375), ('pine', 0.5321435332298279)]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model.most_similar('wood', [], 3))\n",
    "#print(word2vec_model.most_similar('temperature'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #w2v=Feature_Word2Vec(modelFilename=word2vec_model_path)#modelFilename=word2vec_model_path\n",
    "# w2v=Feature_Word2Vec()\n",
    "# #sentences=w2v.convertDFIntoSentences(product_df,'content')\n",
    "# #print(sentences)\n",
    "# w2v.trainModel(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(w2v.model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# w2vExpand=Word2VecQueryExpansion(modelFilename=word2vec_model_path)\n",
    "# query=\"cooking\"\n",
    "# print(\"Expanding query: \")\n",
    "# print(w2vExpand.getExpandedQuery(query,maxNoOfAdditionalWords=2,minSimilarityLevel=0.65,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(w2v.getVectorFromWord('wood'))\n",
    "# print(w2v.getSimilarWordVectors('wood',5))\n",
    "# print(len(w2v.getVectorFromWord('wood')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embeddings to keras\n",
    "http://ben.bolte.cc/resources/embeddings/embeddings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vocab = dict([(k, v.index) for k, v in w2v.model.wv.vocab.items()])\n",
    "#vocab = dict([(k, v.index) for k, v in word2vec_model.wv.vocab.items()])\n",
    "word2vec_vocab = dict([(k, v.index+2) for k, v in word2vec_model.wv.vocab.items()]) # Leave room for <pad>\n",
    "word2vec_vocab['<PAD>']=0\n",
    "word2vec_vocab['<OOV>']=1\n",
    "with open(vocab_path, 'w') as f:\n",
    "    f.write(json.dumps(word2vec_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weights = w2v.model.wv.syn0\n",
    "weights = word2vec_model.wv.syn0\n",
    "np.save(open(embeddings_path, 'wb'), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vocab(vocab_path):\n",
    "    \"\"\"\n",
    "    Load word -> index and index -> word mappings\n",
    "    :param vocab_path: where the word-index map is saved\n",
    "    :return: word2idx, idx2word\n",
    "    \"\"\"\n",
    "\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    word2idx = data\n",
    "    idx2word = dict([(v, k) for k, v in data.items()])\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx, idx2word = load_vocab(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2vec_embedding_layer(embeddings_path):\n",
    "    \"\"\"\n",
    "    Generate an embedding layer word2vec embeddings\n",
    "    :param embeddings_path: where the embeddings are saved (as a numpy file)\n",
    "    :return: the generated embedding layer\n",
    "    \"\"\"\n",
    "\n",
    "    saved_weights = np.load(open(embeddings_path, 'rb'))\n",
    "    padding_weight = np.zeros(num_features)\n",
    "    padding_weight=np.expand_dims(padding_weight,axis=0)\n",
    "    oov_weight = np.random.rand(num_features)\n",
    "    oov_weight=np.expand_dims(oov_weight,axis=0)    \n",
    "    weights=np.concatenate((padding_weight,saved_weights), axis=0)\n",
    "    layer = Embedding(input_dim=weights.shape[0], output_dim=weights.shape[1], weights=[weights],mask_zero=True, trainable=False)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a = np.load(open(embeddings_path, 'rb'))\n",
    "# b = np.zeros(50)\n",
    "# b=np.expand_dims(b,axis=0)\n",
    "# b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c=np.concatenate((b,a), axis=0)\n",
    "# c[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# idx2word = []\n",
    "# idx2word=[dict([(v, k) for k, v in word2idx.items()])]\n",
    "# idx2word.insert(0, '<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD>'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<OOV>'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_tokens=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variable arguments are passed to gensim's word2vec model\n",
    "# if options.train:\n",
    "#     print('Training Word2Vec...')\n",
    "#     create_embeddings(options.data, options.embeddings, options.vocab, size=100, min_count=5, window=5, sg=1, iter=25)\n",
    "\n",
    "word2idx, idx2word = load_vocab(vocab_path)\n",
    "\n",
    "if print_tokens:\n",
    "    print('Tokens:', ', '.join(word2idx.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104592"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo need to pass in word2idx\n",
    "def convert_word2idx(word,verbose=False):\n",
    "    if verbose:\n",
    "        print(\"word: {}\".format(word))\n",
    "    if str(word) not in word2idx.keys():\n",
    "        return 1\n",
    "    else:\n",
    "        return word2idx[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert_word2idx('bracket')\n",
    "for word in doc_sentences[100]:\n",
    "    idx=convert_word2idx(word)\n",
    "    #print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_sent2idx(sentences):\n",
    "    query_word2vec_idx_list=[]\n",
    "    queries=sentences #w2v.convertDFIntoSentences(df,col)\n",
    "    print(len(queries))\n",
    "    for query in queries:\n",
    "        idx_list = []\n",
    "        for word in query:\n",
    "#             if word not in word2idx.keys():\n",
    "#                 idx_list+=[0]#[len(word2idx.keys())] # use last as special key #TODO: well we need to fix this. Using 0 for now so it's in range To OOV or something random\n",
    "#             else:\n",
    "#                 idx_list+=[word2idx[word]]\n",
    "            idx_list+=[convert_word2idx(word)]\n",
    "        query_word2vec_idx_list+=[idx_list]\n",
    "        #print(\"=====\")\n",
    "        #print(idx_list)\n",
    "        #print(\"=====\")\n",
    "    return query_word2vec_idx_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74067\n"
     ]
    }
   ],
   "source": [
    "#query_word2vec_idx_list = query_sent2idx(train_query_df['search_term'])\n",
    "query_word2vec_idx_list = query_sent2idx(query_sentences)\n",
    "#print(query_word2vec_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def doc_sent2idx(df,col):\n",
    "#     doc_word2vec_idx_list=[]\n",
    "#     for row in df.iteritems():\n",
    "#         a=w2v.convertDFIntoSentences(row,col)\n",
    "#         print(a)\n",
    "# #    print(len(queries))\n",
    "# #     for query in queries:\n",
    "# #         idx_list = []\n",
    "# #         for word in query:\n",
    "# #             if word not in word2idx.keys():\n",
    "# #                 idx_list+=[len(word2idx.keys())] # use last as special key\n",
    "# #             else:\n",
    "# #                 idx_list+=[word2idx[word]]\n",
    "# #         query_word2vec_idx_list+=[idx_list]\n",
    "# #         print(\"=====\")\n",
    "# #         print(idx_list)\n",
    "# #         print(\"=====\")\n",
    "#     return doc_word2vec_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74067\n"
     ]
    }
   ],
   "source": [
    "#TODO: this is fucked. just bodge for testing nn\n",
    "#doc_word2vec_idx_list = query_sent2idx(product_df,'product_title')\n",
    "joined_df=train_query_df.join(product_df.set_index('product_uid'), on='product_uid')\n",
    "\n",
    "joined_doc_sentences=[]\n",
    "for doc in joined_df['content']:\n",
    "    words,vocab = doc_to_wordlist(doc,vocab, remove_stopwords=True)\n",
    "    joined_doc_sentences+=[words]\n",
    "    \n",
    "doc_word2vec_idx_list = query_sent2idx(joined_doc_sentences)\n",
    "#print(doc_word2vec_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74067"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_doc_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1867,\n",
       "  399,\n",
       "  1191,\n",
       "  47,\n",
       "  344,\n",
       "  652,\n",
       "  2876,\n",
       "  196,\n",
       "  1362,\n",
       "  2016,\n",
       "  106,\n",
       "  65,\n",
       "  1271,\n",
       "  886,\n",
       "  1020,\n",
       "  1867,\n",
       "  399,\n",
       "  1191,\n",
       "  90,\n",
       "  138,\n",
       "  211,\n",
       "  2876,\n",
       "  1133,\n",
       "  439,\n",
       "  5102,\n",
       "  75,\n",
       "  16,\n",
       "  114,\n",
       "  1716,\n",
       "  544,\n",
       "  1497,\n",
       "  557,\n",
       "  492,\n",
       "  4695,\n",
       "  11148,\n",
       "  510,\n",
       "  404,\n",
       "  8,\n",
       "  544,\n",
       "  423,\n",
       "  2460,\n",
       "  5,\n",
       "  9686,\n",
       "  509,\n",
       "  321,\n",
       "  1143,\n",
       "  65,\n",
       "  271,\n",
       "  358,\n",
       "  311,\n",
       "  49,\n",
       "  1853,\n",
       "  304,\n",
       "  481,\n",
       "  1180,\n",
       "  521,\n",
       "  801,\n",
       "  1133,\n",
       "  551,\n",
       "  971,\n",
       "  11,\n",
       "  883,\n",
       "  544,\n",
       "  2016,\n",
       "  2051,\n",
       "  2841,\n",
       "  372,\n",
       "  1355,\n",
       "  3099,\n",
       "  127,\n",
       "  477,\n",
       "  1362,\n",
       "  4957,\n",
       "  886,\n",
       "  399,\n",
       "  326,\n",
       "  6,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  28,\n",
       "  47,\n",
       "  344,\n",
       "  15,\n",
       "  463,\n",
       "  271,\n",
       "  311,\n",
       "  358,\n",
       "  121,\n",
       "  7029,\n",
       "  761,\n",
       "  702,\n",
       "  173,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  399,\n",
       "  446,\n",
       "  4364,\n",
       "  252],\n",
       " [1867,\n",
       "  399,\n",
       "  1191,\n",
       "  47,\n",
       "  344,\n",
       "  652,\n",
       "  2876,\n",
       "  196,\n",
       "  1362,\n",
       "  2016,\n",
       "  106,\n",
       "  65,\n",
       "  1271,\n",
       "  886,\n",
       "  1020,\n",
       "  1867,\n",
       "  399,\n",
       "  1191,\n",
       "  90,\n",
       "  138,\n",
       "  211,\n",
       "  2876,\n",
       "  1133,\n",
       "  439,\n",
       "  5102,\n",
       "  75,\n",
       "  16,\n",
       "  114,\n",
       "  1716,\n",
       "  544,\n",
       "  1497,\n",
       "  557,\n",
       "  492,\n",
       "  4695,\n",
       "  11148,\n",
       "  510,\n",
       "  404,\n",
       "  8,\n",
       "  544,\n",
       "  423,\n",
       "  2460,\n",
       "  5,\n",
       "  9686,\n",
       "  509,\n",
       "  321,\n",
       "  1143,\n",
       "  65,\n",
       "  271,\n",
       "  358,\n",
       "  311,\n",
       "  49,\n",
       "  1853,\n",
       "  304,\n",
       "  481,\n",
       "  1180,\n",
       "  521,\n",
       "  801,\n",
       "  1133,\n",
       "  551,\n",
       "  971,\n",
       "  11,\n",
       "  883,\n",
       "  544,\n",
       "  2016,\n",
       "  2051,\n",
       "  2841,\n",
       "  372,\n",
       "  1355,\n",
       "  3099,\n",
       "  127,\n",
       "  477,\n",
       "  1362,\n",
       "  4957,\n",
       "  886,\n",
       "  399,\n",
       "  326,\n",
       "  6,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  28,\n",
       "  47,\n",
       "  344,\n",
       "  15,\n",
       "  463,\n",
       "  271,\n",
       "  311,\n",
       "  358,\n",
       "  121,\n",
       "  7029,\n",
       "  761,\n",
       "  702,\n",
       "  173,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  399,\n",
       "  446,\n",
       "  4364,\n",
       "  252],\n",
       " [596,\n",
       "  179,\n",
       "  825,\n",
       "  362,\n",
       "  2,\n",
       "  257,\n",
       "  4066,\n",
       "  15389,\n",
       "  39014,\n",
       "  20,\n",
       "  289,\n",
       "  432,\n",
       "  596,\n",
       "  179,\n",
       "  825,\n",
       "  362,\n",
       "  826,\n",
       "  93,\n",
       "  34,\n",
       "  432,\n",
       "  809,\n",
       "  928,\n",
       "  2676,\n",
       "  20,\n",
       "  289,\n",
       "  186,\n",
       "  37,\n",
       "  675,\n",
       "  133,\n",
       "  295,\n",
       "  1015,\n",
       "  447,\n",
       "  567,\n",
       "  35,\n",
       "  432,\n",
       "  5869,\n",
       "  2131,\n",
       "  362,\n",
       "  9381,\n",
       "  1608,\n",
       "  170,\n",
       "  49,\n",
       "  281,\n",
       "  905,\n",
       "  593,\n",
       "  1616,\n",
       "  3224,\n",
       "  50,\n",
       "  180,\n",
       "  1804,\n",
       "  596,\n",
       "  117,\n",
       "  5162,\n",
       "  60,\n",
       "  71,\n",
       "  45,\n",
       "  74,\n",
       "  73,\n",
       "  58,\n",
       "  98,\n",
       "  11241,\n",
       "  20,\n",
       "  581,\n",
       "  1228,\n",
       "  3078,\n",
       "  3322,\n",
       "  3405,\n",
       "  4125,\n",
       "  106,\n",
       "  108,\n",
       "  289,\n",
       "  848,\n",
       "  1228,\n",
       "  1973,\n",
       "  11703,\n",
       "  295,\n",
       "  93,\n",
       "  34,\n",
       "  432,\n",
       "  309,\n",
       "  1481,\n",
       "  2571,\n",
       "  4670,\n",
       "  6916,\n",
       "  2266,\n",
       "  2,\n",
       "  9,\n",
       "  26,\n",
       "  35,\n",
       "  393,\n",
       "  25,\n",
       "  13,\n",
       "  305,\n",
       "  441,\n",
       "  183,\n",
       "  10,\n",
       "  4,\n",
       "  1896,\n",
       "  137,\n",
       "  1498,\n",
       "  567,\n",
       "  825,\n",
       "  553,\n",
       "  25,\n",
       "  13,\n",
       "  281,\n",
       "  905,\n",
       "  3224,\n",
       "  1983,\n",
       "  596,\n",
       "  70,\n",
       "  20,\n",
       "  289,\n",
       "  50,\n",
       "  437,\n",
       "  39,\n",
       "  132,\n",
       "  54,\n",
       "  142,\n",
       "  266,\n",
       "  885,\n",
       "  1832,\n",
       "  132,\n",
       "  72,\n",
       "  3883,\n",
       "  17700,\n",
       "  465,\n",
       "  29,\n",
       "  39,\n",
       "  420,\n",
       "  796,\n",
       "  645,\n",
       "  709,\n",
       "  718,\n",
       "  461,\n",
       "  784,\n",
       "  816,\n",
       "  822,\n",
       "  821],\n",
       " [888,\n",
       "  8091,\n",
       "  2,\n",
       "  75,\n",
       "  53,\n",
       "  144,\n",
       "  123,\n",
       "  56,\n",
       "  176,\n",
       "  267,\n",
       "  24,\n",
       "  2225,\n",
       "  205,\n",
       "  888,\n",
       "  8091,\n",
       "  126,\n",
       "  75,\n",
       "  53,\n",
       "  144,\n",
       "  123,\n",
       "  56,\n",
       "  176,\n",
       "  605,\n",
       "  410,\n",
       "  10613,\n",
       "  2309,\n",
       "  297,\n",
       "  370,\n",
       "  656,\n",
       "  267,\n",
       "  679,\n",
       "  17,\n",
       "  191,\n",
       "  843,\n",
       "  6,\n",
       "  944,\n",
       "  2126,\n",
       "  127,\n",
       "  284,\n",
       "  259,\n",
       "  6273,\n",
       "  60,\n",
       "  71,\n",
       "  45,\n",
       "  74,\n",
       "  73,\n",
       "  58,\n",
       "  98,\n",
       "  29,\n",
       "  123,\n",
       "  56,\n",
       "  902,\n",
       "  56,\n",
       "  7718,\n",
       "  8172,\n",
       "  146,\n",
       "  172,\n",
       "  29,\n",
       "  75,\n",
       "  2159,\n",
       "  2315,\n",
       "  216,\n",
       "  401,\n",
       "  626,\n",
       "  17,\n",
       "  277,\n",
       "  267,\n",
       "  2907,\n",
       "  9014,\n",
       "  51,\n",
       "  774,\n",
       "  17,\n",
       "  942,\n",
       "  1972,\n",
       "  960,\n",
       "  170,\n",
       "  2091,\n",
       "  343,\n",
       "  2169,\n",
       "  1196,\n",
       "  2020,\n",
       "  919,\n",
       "  2531,\n",
       "  5,\n",
       "  383,\n",
       "  532,\n",
       "  17,\n",
       "  942,\n",
       "  3507],\n",
       " [888,\n",
       "  8091,\n",
       "  2,\n",
       "  75,\n",
       "  53,\n",
       "  144,\n",
       "  123,\n",
       "  56,\n",
       "  176,\n",
       "  267,\n",
       "  24,\n",
       "  2225,\n",
       "  205,\n",
       "  888,\n",
       "  8091,\n",
       "  126,\n",
       "  75,\n",
       "  53,\n",
       "  144,\n",
       "  123,\n",
       "  56,\n",
       "  176,\n",
       "  605,\n",
       "  410,\n",
       "  10613,\n",
       "  2309,\n",
       "  297,\n",
       "  370,\n",
       "  656,\n",
       "  267,\n",
       "  679,\n",
       "  17,\n",
       "  191,\n",
       "  843,\n",
       "  6,\n",
       "  944,\n",
       "  2126,\n",
       "  127,\n",
       "  284,\n",
       "  259,\n",
       "  6273,\n",
       "  60,\n",
       "  71,\n",
       "  45,\n",
       "  74,\n",
       "  73,\n",
       "  58,\n",
       "  98,\n",
       "  29,\n",
       "  123,\n",
       "  56,\n",
       "  902,\n",
       "  56,\n",
       "  7718,\n",
       "  8172,\n",
       "  146,\n",
       "  172,\n",
       "  29,\n",
       "  75,\n",
       "  2159,\n",
       "  2315,\n",
       "  216,\n",
       "  401,\n",
       "  626,\n",
       "  17,\n",
       "  277,\n",
       "  267,\n",
       "  2907,\n",
       "  9014,\n",
       "  51,\n",
       "  774,\n",
       "  17,\n",
       "  942,\n",
       "  1972,\n",
       "  960,\n",
       "  170,\n",
       "  2091,\n",
       "  343,\n",
       "  2169,\n",
       "  1196,\n",
       "  2020,\n",
       "  919,\n",
       "  2531,\n",
       "  5,\n",
       "  383,\n",
       "  532,\n",
       "  17,\n",
       "  942,\n",
       "  3507],\n",
       " [1543,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  241,\n",
       "  1581,\n",
       "  1424,\n",
       "  86,\n",
       "  15,\n",
       "  965,\n",
       "  411,\n",
       "  6937,\n",
       "  3714,\n",
       "  905,\n",
       "  1352,\n",
       "  2532,\n",
       "  1543,\n",
       "  241,\n",
       "  1424,\n",
       "  1518,\n",
       "  1581,\n",
       "  411,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  250,\n",
       "  102,\n",
       "  3224,\n",
       "  319,\n",
       "  1409,\n",
       "  1021,\n",
       "  5053,\n",
       "  411,\n",
       "  976,\n",
       "  2340,\n",
       "  965,\n",
       "  411,\n",
       "  388,\n",
       "  965,\n",
       "  411,\n",
       "  4052,\n",
       "  411,\n",
       "  2067,\n",
       "  851,\n",
       "  1388,\n",
       "  411,\n",
       "  33,\n",
       "  1581,\n",
       "  5770,\n",
       "  1960,\n",
       "  100,\n",
       "  2226,\n",
       "  8782,\n",
       "  5782,\n",
       "  8719,\n",
       "  5642,\n",
       "  4506,\n",
       "  513,\n",
       "  43,\n",
       "  270,\n",
       "  655,\n",
       "  1559,\n",
       "  43,\n",
       "  1176,\n",
       "  140,\n",
       "  997,\n",
       "  104,\n",
       "  50,\n",
       "  103,\n",
       "  5831,\n",
       "  5368,\n",
       "  474,\n",
       "  165,\n",
       "  5,\n",
       "  1489,\n",
       "  1370,\n",
       "  1157,\n",
       "  1147,\n",
       "  2113,\n",
       "  492,\n",
       "  624,\n",
       "  5368,\n",
       "  1986,\n",
       "  6605,\n",
       "  60,\n",
       "  71,\n",
       "  45,\n",
       "  74,\n",
       "  73,\n",
       "  58,\n",
       "  98,\n",
       "  2132,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  250,\n",
       "  1172,\n",
       "  1399,\n",
       "  1139,\n",
       "  6577,\n",
       "  1409,\n",
       "  39015,\n",
       "  1753,\n",
       "  411,\n",
       "  62,\n",
       "  42,\n",
       "  411,\n",
       "  1279,\n",
       "  196,\n",
       "  411,\n",
       "  6606,\n",
       "  21864,\n",
       "  1360,\n",
       "  1862,\n",
       "  51,\n",
       "  12837,\n",
       "  1440,\n",
       "  914,\n",
       "  1605,\n",
       "  752,\n",
       "  805,\n",
       "  41,\n",
       "  223,\n",
       "  164,\n",
       "  61,\n",
       "  182,\n",
       "  126,\n",
       "  84,\n",
       "  8,\n",
       "  189,\n",
       "  197,\n",
       "  2121,\n",
       "  89,\n",
       "  3423,\n",
       "  16924,\n",
       "  159,\n",
       "  605,\n",
       "  410,\n",
       "  49,\n",
       "  7,\n",
       "  1739,\n",
       "  805,\n",
       "  2550,\n",
       "  965,\n",
       "  4228,\n",
       "  411,\n",
       "  1892,\n",
       "  388,\n",
       "  965,\n",
       "  1892,\n",
       "  588,\n",
       "  914,\n",
       "  4208,\n",
       "  31402,\n",
       "  9759,\n",
       "  345,\n",
       "  3295,\n",
       "  668,\n",
       "  39016,\n",
       "  7120,\n",
       "  270,\n",
       "  345,\n",
       "  1710,\n",
       "  7120,\n",
       "  3080,\n",
       "  411,\n",
       "  983,\n",
       "  62,\n",
       "  1279,\n",
       "  211,\n",
       "  5215,\n",
       "  333,\n",
       "  3784,\n",
       "  5747,\n",
       "  9757,\n",
       "  4365,\n",
       "  6237,\n",
       "  7909,\n",
       "  61247,\n",
       "  273,\n",
       "  1100,\n",
       "  1581,\n",
       "  411,\n",
       "  278,\n",
       "  5291,\n",
       "  110,\n",
       "  1001,\n",
       "  195,\n",
       "  5077,\n",
       "  162,\n",
       "  480,\n",
       "  474,\n",
       "  345,\n",
       "  411,\n",
       "  277,\n",
       "  5813,\n",
       "  655,\n",
       "  1559,\n",
       "  43,\n",
       "  1176,\n",
       "  140,\n",
       "  997,\n",
       "  104,\n",
       "  438,\n",
       "  814,\n",
       "  2711,\n",
       "  1157,\n",
       "  1147,\n",
       "  2113,\n",
       "  492,\n",
       "  624,\n",
       "  5368,\n",
       "  1986,\n",
       "  6605,\n",
       "  708,\n",
       "  4179,\n",
       "  279,\n",
       "  1885,\n",
       "  2487,\n",
       "  411,\n",
       "  1139,\n",
       "  950,\n",
       "  4179,\n",
       "  874,\n",
       "  104,\n",
       "  516,\n",
       "  16,\n",
       "  145,\n",
       "  240,\n",
       "  127,\n",
       "  511,\n",
       "  411,\n",
       "  27123,\n",
       "  299,\n",
       "  195,\n",
       "  949,\n",
       "  741,\n",
       "  195,\n",
       "  659,\n",
       "  223,\n",
       "  1424,\n",
       "  368,\n",
       "  4159,\n",
       "  741,\n",
       "  195,\n",
       "  851,\n",
       "  538,\n",
       "  22,\n",
       "  299,\n",
       "  191,\n",
       "  241,\n",
       "  805,\n",
       "  41,\n",
       "  1424,\n",
       "  368,\n",
       "  3281,\n",
       "  401,\n",
       "  2753,\n",
       "  1737,\n",
       "  1094,\n",
       "  253,\n",
       "  735,\n",
       "  1084,\n",
       "  2054,\n",
       "  1764,\n",
       "  4838,\n",
       "  28920,\n",
       "  1112,\n",
       "  826,\n",
       "  1112,\n",
       "  14,\n",
       "  121,\n",
       "  481,\n",
       "  1614,\n",
       "  21,\n",
       "  1977,\n",
       "  455,\n",
       "  8,\n",
       "  103,\n",
       "  119,\n",
       "  2,\n",
       "  76,\n",
       "  40,\n",
       "  2794,\n",
       "  1862,\n",
       "  254,\n",
       "  2611,\n",
       "  140,\n",
       "  2611,\n",
       "  6677,\n",
       "  136,\n",
       "  211,\n",
       "  19,\n",
       "  61248,\n",
       "  884,\n",
       "  4596,\n",
       "  87,\n",
       "  1453,\n",
       "  426,\n",
       "  33,\n",
       "  3739,\n",
       "  411,\n",
       "  33,\n",
       "  180,\n",
       "  880,\n",
       "  965,\n",
       "  992,\n",
       "  33,\n",
       "  6136,\n",
       "  2047,\n",
       "  699,\n",
       "  109,\n",
       "  4638,\n",
       "  19703,\n",
       "  12699,\n",
       "  4909,\n",
       "  2824,\n",
       "  8548,\n",
       "  1424,\n",
       "  24,\n",
       "  383,\n",
       "  1581,\n",
       "  725,\n",
       "  593,\n",
       "  3199,\n",
       "  6822,\n",
       "  411,\n",
       "  725,\n",
       "  24,\n",
       "  411,\n",
       "  725,\n",
       "  1052,\n",
       "  1424,\n",
       "  175,\n",
       "  1279,\n",
       "  805,\n",
       "  2306,\n",
       "  383,\n",
       "  365,\n",
       "  954,\n",
       "  1474,\n",
       "  24,\n",
       "  776,\n",
       "  1230,\n",
       "  570,\n",
       "  19,\n",
       "  388,\n",
       "  70],\n",
       " [1543,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  241,\n",
       "  1581,\n",
       "  1424,\n",
       "  86,\n",
       "  15,\n",
       "  965,\n",
       "  411,\n",
       "  6937,\n",
       "  3714,\n",
       "  905,\n",
       "  1352,\n",
       "  2532,\n",
       "  1543,\n",
       "  241,\n",
       "  1424,\n",
       "  1518,\n",
       "  1581,\n",
       "  411,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  250,\n",
       "  102,\n",
       "  3224,\n",
       "  319,\n",
       "  1409,\n",
       "  1021,\n",
       "  5053,\n",
       "  411,\n",
       "  976,\n",
       "  2340,\n",
       "  965,\n",
       "  411,\n",
       "  388,\n",
       "  965,\n",
       "  411,\n",
       "  4052,\n",
       "  411,\n",
       "  2067,\n",
       "  851,\n",
       "  1388,\n",
       "  411,\n",
       "  33,\n",
       "  1581,\n",
       "  5770,\n",
       "  1960,\n",
       "  100,\n",
       "  2226,\n",
       "  8782,\n",
       "  5782,\n",
       "  8719,\n",
       "  5642,\n",
       "  4506,\n",
       "  513,\n",
       "  43,\n",
       "  270,\n",
       "  655,\n",
       "  1559,\n",
       "  43,\n",
       "  1176,\n",
       "  140,\n",
       "  997,\n",
       "  104,\n",
       "  50,\n",
       "  103,\n",
       "  5831,\n",
       "  5368,\n",
       "  474,\n",
       "  165,\n",
       "  5,\n",
       "  1489,\n",
       "  1370,\n",
       "  1157,\n",
       "  1147,\n",
       "  2113,\n",
       "  492,\n",
       "  624,\n",
       "  5368,\n",
       "  1986,\n",
       "  6605,\n",
       "  60,\n",
       "  71,\n",
       "  45,\n",
       "  74,\n",
       "  73,\n",
       "  58,\n",
       "  98,\n",
       "  2132,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  250,\n",
       "  1172,\n",
       "  1399,\n",
       "  1139,\n",
       "  6577,\n",
       "  1409,\n",
       "  39015,\n",
       "  1753,\n",
       "  411,\n",
       "  62,\n",
       "  42,\n",
       "  411,\n",
       "  1279,\n",
       "  196,\n",
       "  411,\n",
       "  6606,\n",
       "  21864,\n",
       "  1360,\n",
       "  1862,\n",
       "  51,\n",
       "  12837,\n",
       "  1440,\n",
       "  914,\n",
       "  1605,\n",
       "  752,\n",
       "  805,\n",
       "  41,\n",
       "  223,\n",
       "  164,\n",
       "  61,\n",
       "  182,\n",
       "  126,\n",
       "  84,\n",
       "  8,\n",
       "  189,\n",
       "  197,\n",
       "  2121,\n",
       "  89,\n",
       "  3423,\n",
       "  16924,\n",
       "  159,\n",
       "  605,\n",
       "  410,\n",
       "  49,\n",
       "  7,\n",
       "  1739,\n",
       "  805,\n",
       "  2550,\n",
       "  965,\n",
       "  4228,\n",
       "  411,\n",
       "  1892,\n",
       "  388,\n",
       "  965,\n",
       "  1892,\n",
       "  588,\n",
       "  914,\n",
       "  4208,\n",
       "  31402,\n",
       "  9759,\n",
       "  345,\n",
       "  3295,\n",
       "  668,\n",
       "  39016,\n",
       "  7120,\n",
       "  270,\n",
       "  345,\n",
       "  1710,\n",
       "  7120,\n",
       "  3080,\n",
       "  411,\n",
       "  983,\n",
       "  62,\n",
       "  1279,\n",
       "  211,\n",
       "  5215,\n",
       "  333,\n",
       "  3784,\n",
       "  5747,\n",
       "  9757,\n",
       "  4365,\n",
       "  6237,\n",
       "  7909,\n",
       "  61247,\n",
       "  273,\n",
       "  1100,\n",
       "  1581,\n",
       "  411,\n",
       "  278,\n",
       "  5291,\n",
       "  110,\n",
       "  1001,\n",
       "  195,\n",
       "  5077,\n",
       "  162,\n",
       "  480,\n",
       "  474,\n",
       "  345,\n",
       "  411,\n",
       "  277,\n",
       "  5813,\n",
       "  655,\n",
       "  1559,\n",
       "  43,\n",
       "  1176,\n",
       "  140,\n",
       "  997,\n",
       "  104,\n",
       "  438,\n",
       "  814,\n",
       "  2711,\n",
       "  1157,\n",
       "  1147,\n",
       "  2113,\n",
       "  492,\n",
       "  624,\n",
       "  5368,\n",
       "  1986,\n",
       "  6605,\n",
       "  708,\n",
       "  4179,\n",
       "  279,\n",
       "  1885,\n",
       "  2487,\n",
       "  411,\n",
       "  1139,\n",
       "  950,\n",
       "  4179,\n",
       "  874,\n",
       "  104,\n",
       "  516,\n",
       "  16,\n",
       "  145,\n",
       "  240,\n",
       "  127,\n",
       "  511,\n",
       "  411,\n",
       "  27123,\n",
       "  299,\n",
       "  195,\n",
       "  949,\n",
       "  741,\n",
       "  195,\n",
       "  659,\n",
       "  223,\n",
       "  1424,\n",
       "  368,\n",
       "  4159,\n",
       "  741,\n",
       "  195,\n",
       "  851,\n",
       "  538,\n",
       "  22,\n",
       "  299,\n",
       "  191,\n",
       "  241,\n",
       "  805,\n",
       "  41,\n",
       "  1424,\n",
       "  368,\n",
       "  3281,\n",
       "  401,\n",
       "  2753,\n",
       "  1737,\n",
       "  1094,\n",
       "  253,\n",
       "  735,\n",
       "  1084,\n",
       "  2054,\n",
       "  1764,\n",
       "  4838,\n",
       "  28920,\n",
       "  1112,\n",
       "  826,\n",
       "  1112,\n",
       "  14,\n",
       "  121,\n",
       "  481,\n",
       "  1614,\n",
       "  21,\n",
       "  1977,\n",
       "  455,\n",
       "  8,\n",
       "  103,\n",
       "  119,\n",
       "  2,\n",
       "  76,\n",
       "  40,\n",
       "  2794,\n",
       "  1862,\n",
       "  254,\n",
       "  2611,\n",
       "  140,\n",
       "  2611,\n",
       "  6677,\n",
       "  136,\n",
       "  211,\n",
       "  19,\n",
       "  61248,\n",
       "  884,\n",
       "  4596,\n",
       "  87,\n",
       "  1453,\n",
       "  426,\n",
       "  33,\n",
       "  3739,\n",
       "  411,\n",
       "  33,\n",
       "  180,\n",
       "  880,\n",
       "  965,\n",
       "  992,\n",
       "  33,\n",
       "  6136,\n",
       "  2047,\n",
       "  699,\n",
       "  109,\n",
       "  4638,\n",
       "  19703,\n",
       "  12699,\n",
       "  4909,\n",
       "  2824,\n",
       "  8548,\n",
       "  1424,\n",
       "  24,\n",
       "  383,\n",
       "  1581,\n",
       "  725,\n",
       "  593,\n",
       "  3199,\n",
       "  6822,\n",
       "  411,\n",
       "  725,\n",
       "  24,\n",
       "  411,\n",
       "  725,\n",
       "  1052,\n",
       "  1424,\n",
       "  175,\n",
       "  1279,\n",
       "  805,\n",
       "  2306,\n",
       "  383,\n",
       "  365,\n",
       "  954,\n",
       "  1474,\n",
       "  24,\n",
       "  776,\n",
       "  1230,\n",
       "  570,\n",
       "  19,\n",
       "  388,\n",
       "  70],\n",
       " [1543,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  241,\n",
       "  1581,\n",
       "  1424,\n",
       "  86,\n",
       "  15,\n",
       "  965,\n",
       "  411,\n",
       "  6937,\n",
       "  3714,\n",
       "  905,\n",
       "  1352,\n",
       "  2532,\n",
       "  1543,\n",
       "  241,\n",
       "  1424,\n",
       "  1518,\n",
       "  1581,\n",
       "  411,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  250,\n",
       "  102,\n",
       "  3224,\n",
       "  319,\n",
       "  1409,\n",
       "  1021,\n",
       "  5053,\n",
       "  411,\n",
       "  976,\n",
       "  2340,\n",
       "  965,\n",
       "  411,\n",
       "  388,\n",
       "  965,\n",
       "  411,\n",
       "  4052,\n",
       "  411,\n",
       "  2067,\n",
       "  851,\n",
       "  1388,\n",
       "  411,\n",
       "  33,\n",
       "  1581,\n",
       "  5770,\n",
       "  1960,\n",
       "  100,\n",
       "  2226,\n",
       "  8782,\n",
       "  5782,\n",
       "  8719,\n",
       "  5642,\n",
       "  4506,\n",
       "  513,\n",
       "  43,\n",
       "  270,\n",
       "  655,\n",
       "  1559,\n",
       "  43,\n",
       "  1176,\n",
       "  140,\n",
       "  997,\n",
       "  104,\n",
       "  50,\n",
       "  103,\n",
       "  5831,\n",
       "  5368,\n",
       "  474,\n",
       "  165,\n",
       "  5,\n",
       "  1489,\n",
       "  1370,\n",
       "  1157,\n",
       "  1147,\n",
       "  2113,\n",
       "  492,\n",
       "  624,\n",
       "  5368,\n",
       "  1986,\n",
       "  6605,\n",
       "  60,\n",
       "  71,\n",
       "  45,\n",
       "  74,\n",
       "  73,\n",
       "  58,\n",
       "  98,\n",
       "  2132,\n",
       "  2,\n",
       "  173,\n",
       "  373,\n",
       "  10,\n",
       "  250,\n",
       "  1172,\n",
       "  1399,\n",
       "  1139,\n",
       "  6577,\n",
       "  1409,\n",
       "  39015,\n",
       "  1753,\n",
       "  411,\n",
       "  62,\n",
       "  42,\n",
       "  411,\n",
       "  1279,\n",
       "  196,\n",
       "  411,\n",
       "  6606,\n",
       "  21864,\n",
       "  1360,\n",
       "  1862,\n",
       "  51,\n",
       "  12837,\n",
       "  1440,\n",
       "  914,\n",
       "  1605,\n",
       "  752,\n",
       "  805,\n",
       "  41,\n",
       "  223,\n",
       "  164,\n",
       "  61,\n",
       "  182,\n",
       "  126,\n",
       "  84,\n",
       "  8,\n",
       "  189,\n",
       "  197,\n",
       "  2121,\n",
       "  89,\n",
       "  3423,\n",
       "  16924,\n",
       "  159,\n",
       "  605,\n",
       "  410,\n",
       "  49,\n",
       "  7,\n",
       "  1739,\n",
       "  805,\n",
       "  2550,\n",
       "  965,\n",
       "  4228,\n",
       "  411,\n",
       "  1892,\n",
       "  388,\n",
       "  965,\n",
       "  1892,\n",
       "  588,\n",
       "  914,\n",
       "  4208,\n",
       "  31402,\n",
       "  9759,\n",
       "  345,\n",
       "  3295,\n",
       "  668,\n",
       "  39016,\n",
       "  7120,\n",
       "  270,\n",
       "  345,\n",
       "  1710,\n",
       "  7120,\n",
       "  3080,\n",
       "  411,\n",
       "  983,\n",
       "  62,\n",
       "  1279,\n",
       "  211,\n",
       "  5215,\n",
       "  333,\n",
       "  3784,\n",
       "  5747,\n",
       "  9757,\n",
       "  4365,\n",
       "  6237,\n",
       "  7909,\n",
       "  61247,\n",
       "  273,\n",
       "  1100,\n",
       "  1581,\n",
       "  411,\n",
       "  278,\n",
       "  5291,\n",
       "  110,\n",
       "  1001,\n",
       "  195,\n",
       "  5077,\n",
       "  162,\n",
       "  480,\n",
       "  474,\n",
       "  345,\n",
       "  411,\n",
       "  277,\n",
       "  5813,\n",
       "  655,\n",
       "  1559,\n",
       "  43,\n",
       "  1176,\n",
       "  140,\n",
       "  997,\n",
       "  104,\n",
       "  438,\n",
       "  814,\n",
       "  2711,\n",
       "  1157,\n",
       "  1147,\n",
       "  2113,\n",
       "  492,\n",
       "  624,\n",
       "  5368,\n",
       "  1986,\n",
       "  6605,\n",
       "  708,\n",
       "  4179,\n",
       "  279,\n",
       "  1885,\n",
       "  2487,\n",
       "  411,\n",
       "  1139,\n",
       "  950,\n",
       "  4179,\n",
       "  874,\n",
       "  104,\n",
       "  516,\n",
       "  16,\n",
       "  145,\n",
       "  240,\n",
       "  127,\n",
       "  511,\n",
       "  411,\n",
       "  27123,\n",
       "  299,\n",
       "  195,\n",
       "  949,\n",
       "  741,\n",
       "  195,\n",
       "  659,\n",
       "  223,\n",
       "  1424,\n",
       "  368,\n",
       "  4159,\n",
       "  741,\n",
       "  195,\n",
       "  851,\n",
       "  538,\n",
       "  22,\n",
       "  299,\n",
       "  191,\n",
       "  241,\n",
       "  805,\n",
       "  41,\n",
       "  1424,\n",
       "  368,\n",
       "  3281,\n",
       "  401,\n",
       "  2753,\n",
       "  1737,\n",
       "  1094,\n",
       "  253,\n",
       "  735,\n",
       "  1084,\n",
       "  2054,\n",
       "  1764,\n",
       "  4838,\n",
       "  28920,\n",
       "  1112,\n",
       "  826,\n",
       "  1112,\n",
       "  14,\n",
       "  121,\n",
       "  481,\n",
       "  1614,\n",
       "  21,\n",
       "  1977,\n",
       "  455,\n",
       "  8,\n",
       "  103,\n",
       "  119,\n",
       "  2,\n",
       "  76,\n",
       "  40,\n",
       "  2794,\n",
       "  1862,\n",
       "  254,\n",
       "  2611,\n",
       "  140,\n",
       "  2611,\n",
       "  6677,\n",
       "  136,\n",
       "  211,\n",
       "  19,\n",
       "  61248,\n",
       "  884,\n",
       "  4596,\n",
       "  87,\n",
       "  1453,\n",
       "  426,\n",
       "  33,\n",
       "  3739,\n",
       "  411,\n",
       "  33,\n",
       "  180,\n",
       "  880,\n",
       "  965,\n",
       "  992,\n",
       "  33,\n",
       "  6136,\n",
       "  2047,\n",
       "  699,\n",
       "  109,\n",
       "  4638,\n",
       "  19703,\n",
       "  12699,\n",
       "  4909,\n",
       "  2824,\n",
       "  8548,\n",
       "  1424,\n",
       "  24,\n",
       "  383,\n",
       "  1581,\n",
       "  725,\n",
       "  593,\n",
       "  3199,\n",
       "  6822,\n",
       "  411,\n",
       "  725,\n",
       "  24,\n",
       "  411,\n",
       "  725,\n",
       "  1052,\n",
       "  1424,\n",
       "  175,\n",
       "  1279,\n",
       "  805,\n",
       "  2306,\n",
       "  383,\n",
       "  365,\n",
       "  954,\n",
       "  1474,\n",
       "  24,\n",
       "  776,\n",
       "  1230,\n",
       "  570,\n",
       "  19,\n",
       "  388,\n",
       "  70],\n",
       " [2217,\n",
       "  139,\n",
       "  9874,\n",
       "  4,\n",
       "  16,\n",
       "  85,\n",
       "  82,\n",
       "  1910,\n",
       "  360,\n",
       "  306,\n",
       "  9874,\n",
       "  99,\n",
       "  4,\n",
       "  16,\n",
       "  82,\n",
       "  85,\n",
       "  1910,\n",
       "  139,\n",
       "  306,\n",
       "  2217,\n",
       "  139,\n",
       "  26,\n",
       "  574,\n",
       "  551,\n",
       "  517,\n",
       "  1657,\n",
       "  2269,\n",
       "  2588,\n",
       "  62,\n",
       "  926,\n",
       "  1727,\n",
       "  16,\n",
       "  180,\n",
       "  258,\n",
       "  511,\n",
       "  1055,\n",
       "  14,\n",
       "  4,\n",
       "  1318,\n",
       "  306,\n",
       "  55,\n",
       "  69,\n",
       "  2022,\n",
       "  610,\n",
       "  676,\n",
       "  148,\n",
       "  19,\n",
       "  675,\n",
       "  82,\n",
       "  190,\n",
       "  2304,\n",
       "  67,\n",
       "  61249,\n",
       "  99,\n",
       "  1318,\n",
       "  349,\n",
       "  933,\n",
       "  16,\n",
       "  492,\n",
       "  3601,\n",
       "  116,\n",
       "  2034,\n",
       "  849,\n",
       "  464,\n",
       "  25,\n",
       "  1103,\n",
       "  25,\n",
       "  311,\n",
       "  635,\n",
       "  781,\n",
       "  82,\n",
       "  1285,\n",
       "  337,\n",
       "  188,\n",
       "  2807,\n",
       "  37,\n",
       "  82,\n",
       "  42,\n",
       "  251,\n",
       "  231,\n",
       "  94,\n",
       "  322,\n",
       "  85,\n",
       "  849,\n",
       "  467,\n",
       "  64,\n",
       "  587,\n",
       "  14,\n",
       "  963,\n",
       "  231,\n",
       "  94,\n",
       "  3112,\n",
       "  5029,\n",
       "  203,\n",
       "  568,\n",
       "  551,\n",
       "  1519,\n",
       "  250,\n",
       "  46023,\n",
       "  906,\n",
       "  3066,\n",
       "  2254,\n",
       "  649,\n",
       "  4653,\n",
       "  149,\n",
       "  103,\n",
       "  850,\n",
       "  21,\n",
       "  227,\n",
       "  342,\n",
       "  1157,\n",
       "  1465,\n",
       "  285],\n",
       " [536,\n",
       "  4197,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  18,\n",
       "  10,\n",
       "  1317,\n",
       "  2629,\n",
       "  2386,\n",
       "  341,\n",
       "  536,\n",
       "  4197,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  6,\n",
       "  3,\n",
       "  18,\n",
       "  10,\n",
       "  1317,\n",
       "  2629,\n",
       "  2386,\n",
       "  184,\n",
       "  452,\n",
       "  49,\n",
       "  102,\n",
       "  245,\n",
       "  664,\n",
       "  50,\n",
       "  94,\n",
       "  4154,\n",
       "  274,\n",
       "  409,\n",
       "  510,\n",
       "  160,\n",
       "  476,\n",
       "  850,\n",
       "  103,\n",
       "  46,\n",
       "  49,\n",
       "  315,\n",
       "  258,\n",
       "  1163,\n",
       "  184,\n",
       "  1332,\n",
       "  197,\n",
       "  102,\n",
       "  404,\n",
       "  60,\n",
       "  71,\n",
       "  45,\n",
       "  74,\n",
       "  73,\n",
       "  58,\n",
       "  98,\n",
       "  28,\n",
       "  664,\n",
       "  25454,\n",
       "  409,\n",
       "  510,\n",
       "  160,\n",
       "  25,\n",
       "  423,\n",
       "  104,\n",
       "  16925,\n",
       "  163]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word2vec_idx_list[0:10]\n",
    "#query_word2vec_idx_list[100:110]\n",
    "#query_sent2idx(joined_doc_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # cosine similarity model\n",
    "# print('Building model...')\n",
    "# input_a = Input(shape=(1,), dtype='int32', name='input_a')\n",
    "# input_b = Input(shape=(1,), dtype='int32', name='input_b')\n",
    "# embeddings = word2vec_embedding_layer(embeddings_path)\n",
    "# embedding_a = embeddings(input_a)\n",
    "# embedding_b = embeddings(input_b)\n",
    "# similarity = merge([embedding_a, embedding_b], mode='cos', dot_axes=2)\n",
    "# model = Model(input=[input_a, input_b], output=similarity)\n",
    "# model.compile(optimizer='sgd', loss='mse') # optimizer and loss don't matter\n",
    "\n",
    "\n",
    "# word_a = 'wood'#raw_input('First word: ')\n",
    "# if word_a not in word2idx:\n",
    "#     print('\"%s\" is not in the index' % word_a)\n",
    "# word_b = 'fan'#raw_input('Second word: ')\n",
    "# if word_b not in word2idx:\n",
    "#     print('\"%s\" is not in the index' % word_b)\n",
    "# output = model.predict([np.asarray([word2idx[word_a]]), np.asarray([word2idx[word_b]])])\n",
    "# print('%f' % output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "6\n",
      "24\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "query_min_len = len(min(query_word2vec_idx_list,key=len)) #400 # todo: confirm this is sensible\n",
    "doc_min_len = len(min(doc_word2vec_idx_list,key=len)) #400 # todo: confirm this is sensible\n",
    "query_max_len = 6 #covers 95.74% of the search lengths (see data exploration)\n",
    "# find longest sub list\n",
    "doc_max_len = 100 #len(max(doc_word2vec_idx_list,key=len)) #400 # todo: confirm this is sensible\n",
    "print(doc_max_len)\n",
    "print(query_max_len)\n",
    "print(doc_min_len)\n",
    "print(query_min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths=[]\n",
    "for i in doc_word2vec_idx_list:\n",
    "    lengths+=[len(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  7.26000000e+02,   7.45400000e+03,   1.34520000e+04,\n",
       "          1.20920000e+04,   1.03880000e+04,   8.10700000e+03,\n",
       "          5.58600000e+03,   4.32800000e+03,   3.15900000e+03,\n",
       "          2.48700000e+03,   1.82500000e+03,   1.36700000e+03,\n",
       "          8.76000000e+02,   5.84000000e+02,   4.39000000e+02,\n",
       "          3.75000000e+02,   2.24000000e+02,   1.41000000e+02,\n",
       "          1.10000000e+02,   8.40000000e+01,   8.90000000e+01,\n",
       "          4.30000000e+01,   3.40000000e+01,   2.00000000e+01,\n",
       "          1.30000000e+01,   1.50000000e+01,   1.50000000e+01,\n",
       "          2.00000000e+00,   1.00000000e+00,   1.10000000e+01,\n",
       "          0.00000000e+00,   3.00000000e+00,   8.00000000e+00,\n",
       "          5.00000000e+00,   2.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00]),\n",
       " array([  24.  ,   41.96,   59.92,   77.88,   95.84,  113.8 ,  131.76,\n",
       "         149.72,  167.68,  185.64,  203.6 ,  221.56,  239.52,  257.48,\n",
       "         275.44,  293.4 ,  311.36,  329.32,  347.28,  365.24,  383.2 ,\n",
       "         401.16,  419.12,  437.08,  455.04,  473.  ,  490.96,  508.92,\n",
       "         526.88,  544.84,  562.8 ,  580.76,  598.72,  616.68,  634.64,\n",
       "         652.6 ,  670.56,  688.52,  706.48,  724.44,  742.4 ,  760.36,\n",
       "         778.32,  796.28,  814.24,  832.2 ,  850.16,  868.12,  886.08,\n",
       "         904.04,  922.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQZLUYThIkjoMB0lSx/8HCSxWcJOijlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7ae851438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(lengths,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_query (InputLayer)         (None, 6)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_doc (InputLayer)           (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          multiple              10459100                                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  multiple              4040                                         \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 6, 30)         17040                                        \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 100, 30)       17040                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 6, 50)         1550                                         \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100, 50)       1550                                         \n",
      "____________________________________________________________________________________________________\n",
      "input_exact_match (InputLayer)   (None, 6, 100)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_1 (Dot)                      (None, 6, 100)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 6, 100)        10100                                        \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 6, 100, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 6, 100, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 6, 100, 2)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 4, 98, 18)     342                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 4, 97, 18)     450                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 4, 96, 18)     558                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 4, 98, 20)     380                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 4, 97, 20)     380                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 4, 96, 20)     380                                          \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalMa (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalMa (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalMa (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 13)            273                                          \n",
      "====================================================================================================\n",
      "Total params: 10,513,183\n",
      "Trainable params: 54,083\n",
      "Non-trainable params: 10,459,100\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TODO testing\n",
    "#doc_max_len=doc_min_len\n",
    "print('Building model...')\n",
    "\n",
    "def get_R(x):\n",
    "    a, b = x.values()\n",
    "    return K.dot(a, b)\n",
    "\n",
    "\n",
    "embeddings = word2vec_embedding_layer(embeddings_path)\n",
    "\n",
    "#embedding lookup\n",
    "# TODO: replace this with embedding with mask zero rather than padding, need to change index for encoding too, imput dim too.\n",
    "# TODO: OOV embedding\n",
    "input_query = Input(shape=(query_max_len,), dtype='int32', name='input_query')\n",
    "input_doc = Input(shape=(doc_max_len,), dtype='int32', name='input_doc')\n",
    "input_exact_match = Input(shape=(query_max_len,doc_max_len), dtype='float32', name='input_exact_match')\n",
    "input_doc = Input(shape=(doc_max_len,), dtype='int32', name='input_doc')\n",
    "embedding_query = embeddings(input_query)  # (None, 6, 100)\n",
    "embedding_doc = embeddings(input_doc)      # (None, 400, 100)\n",
    "\n",
    "#shared linear projection\n",
    "shared_lp = Dense(40,activation='linear')\n",
    "query_output = shared_lp(embedding_query) # (None, 6, 40) \n",
    "doc_output = shared_lp(embedding_doc) #(None, 400, 40) \n",
    "\n",
    "#query: bi LSTM, lp -- implementation = 0 for CPU option, 1 or 2 for GPU\n",
    "query_output = Bidirectional(LSTM(30, dropout=0.0, implementation=2, return_sequences=True, go_backwards=True,use_bias=True,unit_forget_bias=True,)\\\n",
    "                             ,merge_mode='mul'#TODO: alts are 'sum','mul','ave','concat'<--default, None\n",
    "                            )(query_output) #(None, 6, 30) unless concat (None, 6, 60)  \n",
    "query_output = Dense(50,activation='linear')(query_output) #(None, 50)\n",
    "\n",
    "#doc: bi LSTM, lp\n",
    "doc_output = Bidirectional(LSTM(30, dropout=0.0, implementation=2, return_sequences=True, go_backwards=True,use_bias=True,unit_forget_bias=True,)\\\n",
    "                             ,merge_mode='mul'#TODO: alts are 'sum','mul','ave','concat'<--default, None\n",
    "                            )(doc_output) #(None, 6, 400) unless concat (None, 6, 800)  \n",
    "doc_output = Dense(50,activation='linear')(doc_output) #(None, 50)\n",
    "\n",
    "#2d product\n",
    "#mt_input = batch_dot(query_output,doc_output,axes=None) #axes=[2,2])\n",
    "#query_output = Flatten()(query_output)\n",
    "#doc_output = Flatten()(doc_output)\n",
    "#mt_input = multiply([query_output, doc_output])\n",
    "#mt_input = dot([query_output, doc_output], axes=(0), normalize=False)  \n",
    "dot_product_output = dot([query_output, doc_output], axes=(2), normalize=True)  \n",
    "#output is (11, 6, 400), where did 50 go?\n",
    "def func_expand_dims(x):\n",
    "    return expand_dims(x, axis=-1)\n",
    "\n",
    "def expand_dims_output_shape(input_shape):\n",
    "    return (input_shape[0], input_shape[1],input_shape[2],1)\n",
    "\n",
    "mt_input_1 = Lambda(func_expand_dims, expand_dims_output_shape)(dot_product_output)\n",
    "\n",
    "#mt_input = dot([transpose(query_output), transpose(doc_output)], axes=(0), normalize=False)  \n",
    "######################################\n",
    "\n",
    "def state_layer_dot_prod(x):\n",
    "    output_list=[]\n",
    "#    output = dot([x[0], x[1]], axes=(2), normalize=False)  \n",
    "    for i in range(50):\n",
    "        print(i)\n",
    "        print(x[0][i])\n",
    "        print(x[1][i])\n",
    "        #output = multiply([transpose(x[0][i]), x[1][i]])\n",
    "        #output_list += output\n",
    "        #output = dot([x[0][i], transpose(x[1][i])])\n",
    "        #transpose(x[1][i])\n",
    "    print(output_list)\n",
    "    return output_list\n",
    "\n",
    "def state_layer_dot_prod_shape(input_shape):\n",
    "    'Merge output shape'\n",
    "    shape = list(input_shape)\n",
    "    #print(input_shape)\n",
    "    #print(shape)\n",
    "    outshape = (shape[0][0],shape[1][1],shape[0][1],shape[0][2])\n",
    "    #print(outshape)\n",
    "    return tuple(outshape)\n",
    "\n",
    "######################################\n",
    "#mt_input = Lambda(state_layer_dot_prod,output_shape=state_layer_dot_prod_shape)([transpose(query_output), transpose(doc_output)])\n",
    "#mt_input = Lambda(state_layer_dot_prod,output_shape=state_layer_dot_prod_shape)([query_output, doc_output])\n",
    "\n",
    "##TODO fix error:\n",
    "#InvalidArgumentError: Input to reshape is a tensor with 4800 values, but the requested shape requires a multiple of 120000\n",
    "#[[Node: reshape_23/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](lambda_40/dot_42/MatMul, reshape_23/Reshape/shape)]]\n",
    "#mt_input = Reshape((doc_max_len, query_max_len,50))(mt_input)\n",
    "\n",
    "#Append exact match channel\n",
    "output_exact_match = Dense(doc_max_len,activation='linear')(input_exact_match)\n",
    "mt_input_2 = Lambda(func_expand_dims, expand_dims_output_shape)(output_exact_match)\n",
    "# mt_input = concatenate([mt_input_1,mt_input_2],axis=0)\n",
    "mt_input = concatenate([mt_input_1,mt_input_2],axis=3)\n",
    "#TODO testing\n",
    "#mt_input = mt_input_1\n",
    "\n",
    "# Conv layers 1\n",
    "output1 = Conv2D(filters=18, kernel_size=(3, 3), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(mt_input)\n",
    "\n",
    "output2 = Conv2D(filters=18, kernel_size=(3, 4), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(mt_input)\n",
    "\n",
    "output3 = Conv2D(filters=18, kernel_size=(3, 5), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(mt_input)\n",
    "\n",
    "# Conv layers 2\n",
    "output1 = Conv2D(filters=20, kernel_size=(1, 1), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(output1)\n",
    "\n",
    "output2 = Conv2D(filters=20, kernel_size=(1, 1), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(output2)\n",
    "\n",
    "output3 = Conv2D(filters=20, kernel_size=(1, 1), strides=(1,1), padding='valid', data_format='channels_last', \\\n",
    "                dilation_rate=(1, 1), activation='relu', use_bias=True, kernel_initializer='glorot_uniform', \\\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, \\\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(output3)\n",
    "\n",
    "# Max pool layer\n",
    "output1 = GlobalMaxPooling2D(data_format='channels_last')(output1)\n",
    "output2 = GlobalMaxPooling2D(data_format='channels_last')(output2)\n",
    "output3 = GlobalMaxPooling2D(data_format='channels_last')(output3)\n",
    "\n",
    "# Merge\n",
    "output_combined = add([output1,output2,output3])\n",
    "#TODO testing\n",
    "#output_combined = output1\n",
    "\n",
    "# Final layer\n",
    "#output = Dense(1,activation='sigmoid')(output_combined)\n",
    "#categorical\n",
    "output = Dense(13, activation='softmax', kernel_initializer='glorot_uniform')(output_combined)\n",
    "\n",
    "\n",
    "# build model\n",
    "#model = Model([input_query], [query_output])\n",
    "#model = Model([input_doc], [encoded_doc])\n",
    "#model = Model([input_query,input_doc], [output1,output2,output3])\n",
    "#model = Model([input_query,input_doc], [output_combined])\n",
    "#model = Model([input_query,input_doc,input_exact_match], [query_output])\n",
    "#model = Model([input_query,input_doc], [query_output,doc_output])\n",
    "#model = Model([input_query,input_doc], [output])\n",
    "#model = Model([input_query,input_doc,input_exact_match], [mt_input])\n",
    "#model = Model([input_query,input_doc,input_exact_match], [mt_input_1,mt_input_2])\n",
    "model = Model([input_query,input_doc,input_exact_match], [output])\n",
    "#model = Model([input_query,input_doc,input_exact_match], [dot_product_output])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #TODO SSM\n",
    "# #doc_max_len=doc_min_len\n",
    "# print('Building model...')\n",
    "\n",
    "# def get_R(x):\n",
    "#     a, b = x.values()\n",
    "#     return K.dot(a, b)\n",
    "\n",
    "\n",
    "# embeddings = word2vec_embedding_layer(embeddings_path)\n",
    "\n",
    "# #embedding lookup\n",
    "# # TODO: replace this with embedding with mask zero rather than padding, need to change index for encoding too, imput dim too.\n",
    "# # TODO: OOV embedding\n",
    "# input_query = Input(shape=(query_max_len,), dtype='int32', name='input_query')\n",
    "# input_doc = Input(shape=(doc_max_len,), dtype='int32', name='input_doc')\n",
    "# input_exact_match = Input(shape=(query_max_len,doc_max_len), dtype='float32', name='input_exact_match')\n",
    "# input_doc = Input(shape=(doc_max_len,), dtype='int32', name='input_doc')\n",
    "# embedding_query = embeddings(input_query)  # (None, 6, 100)\n",
    "# embedding_doc = embeddings(input_doc)      # (None, 400, 100)\n",
    "\n",
    "# #shared linear projection\n",
    "# shared_lp = Dense(40,activation='linear')\n",
    "# query_output = shared_lp(embedding_query) # (None, 6, 40) \n",
    "# doc_output = shared_lp(embedding_doc) #(None, 400, 40) \n",
    "\n",
    "# #query: bi LSTM, lp -- implementation = 0 for CPU option, 1 or 2 for GPU\n",
    "# query_output = Bidirectional(LSTM(16, dropout=0.0, implementation=0, return_sequences=True, go_backwards=True)\\\n",
    "#                              ,merge_mode='mul'#TODO: alts are 'sum','mul','ave','concat'<--default, None\n",
    "#                             )(query_output) #(None, 6, 30) unless concat (None, 6, 60)  \n",
    "# query_output = Dense(50,activation='linear')(query_output) #(None, 50)\n",
    "\n",
    "# #doc: bi LSTM, lp\n",
    "# doc_output = Bidirectional(LSTM(64, dropout=0.0, implementation=0, return_sequences=True, go_backwards=True)\\\n",
    "#                              ,merge_mode='mul'#TODO: alts are 'sum','mul','ave','concat'<--default, None\n",
    "#                             )(doc_output) #(None, 6, 400) unless concat (None, 6, 800)  \n",
    "# doc_output = Dense(50,activation='linear')(doc_output) #(None, 50)\n",
    "\n",
    "# #2d product\n",
    "# #mt_input = batch_dot(query_output,doc_output,axes=None) #axes=[2,2])\n",
    "# #query_output = Flatten()(query_output)\n",
    "# #doc_output = Flatten()(doc_output)\n",
    "# #mt_input = multiply([query_output, doc_output])\n",
    "# #mt_input = dot([query_output, doc_output], axes=(0), normalize=False)  \n",
    "# dot_product_output = dot([query_output, doc_output], axes=(2), normalize=True)  \n",
    "# #output is (11, 6, 400), where did 50 go?\n",
    "# def func_expand_dims(x):\n",
    "#     return expand_dims(x, axis=-1)\n",
    "\n",
    "# def expand_dims_output_shape(input_shape):\n",
    "#     return (input_shape[0], input_shape[1],input_shape[2],1)\n",
    "\n",
    "# mt_input_1 = Lambda(func_expand_dims, expand_dims_output_shape)(dot_product_output)\n",
    "\n",
    "\n",
    "# # Merge\n",
    "# #output_combined = add([output1,output2,output3])\n",
    "# #TODO testing\n",
    "# output1 = GlobalMaxPooling2D(data_format='channels_last')(mt_input_1)\n",
    "# output_combined = output1\n",
    "\n",
    "\n",
    "# # Final layer\n",
    "# output = Dense(1,activation='sigmoid')(output_combined)\n",
    "# #categorical\n",
    "# #output = Dense(13, activation='softmax', kernel_initializer='glorot_uniform', use_bias=True)(output_combined)\n",
    "\n",
    "\n",
    "# # build model\n",
    "# #model = Model([input_query], [query_output])\n",
    "# #model = Model([input_doc], [encoded_doc])\n",
    "# #model = Model([input_query,input_doc], [output1,output2,output3])\n",
    "# #model = Model([input_query,input_doc], [output_combined])\n",
    "# #model = Model([input_query,input_doc,input_exact_match], [query_output])\n",
    "# #model = Model([input_query,input_doc], [query_output,doc_output])\n",
    "# #model = Model([input_query,input_doc], [output])\n",
    "# #model = Model([input_query,input_doc,input_exact_match], [mt_input])\n",
    "# #model = Model([input_query,input_doc,input_exact_match], [mt_input_1,mt_input_2])\n",
    "# model = Model([input_query,input_doc,input_exact_match], [output])\n",
    "\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # from keras.layers import Input, merge\n",
    "# # from keras.models import Model\n",
    "# # import numpy as np\n",
    "\n",
    "# # input_a = np.reshape([[1, 2, 3],[1, 2, 3],],[[1, 2, 3],[1, 2, 3]])\n",
    "# # input_b = np.reshape([4, 5, 6], (1, 1, 3))\n",
    "\n",
    "# # print(input_a)\n",
    "# # print(input_b)\n",
    "# # a = Input(shape=(1, 3))\n",
    "# # b = Input(shape=(1, 3))\n",
    "\n",
    "# # concat = merge([a, b], mode='concat', concat_axis=-1)\n",
    "# # dot = merge([a, b], mode='dot', dot_axes=2)\n",
    "# # cos = merge([a, b], mode='cos', dot_axes=2)\n",
    "\n",
    "# # model_concat = Model(input=[a, b], output=concat)\n",
    "# # model_dot = Model(input=[a, b], output=dot)\n",
    "# # model_cos = Model(input=[a, b], output=cos)\n",
    "\n",
    "# # print(model_concat.predict([input_a, input_b]))\n",
    "# # print(model_dot.predict([input_a, input_b]))\n",
    "# # print(model_cos.predict([input_a, input_b]))\n",
    "\n",
    "# from keras import backend as K\n",
    "# x_batch = K.ones(shape=(11, 6,50 ))\n",
    "# y_batch = K.ones(shape=(11, 400,50))\n",
    "# x_batch=K.batch_flatten(x_batch)\n",
    "# y_batch=K.batch_flatten(y_batch)\n",
    "# #xy_batch_dot = K.dot(transpose(y_batch),x_batch )#, axes=[0,0])\n",
    "# xy_batch_dot = K.batch_dot(x_batch,y_batch, axes=[0,0])\n",
    "# K.int_shape(xy_batch_dot)\n",
    "# # K.int_shape(x_batch)\n",
    "# # K.int_shape(y_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "#optimizer = optimizers.SGD(lr = 0.001, momentum = 0.9, decay = 0.0, nesterov = True)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
    "#model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_query_train shape: (74067, 6)\n",
      "x_doc_train shape: (74067, 100)\n",
      "y_train shape: (74067, 13)\n"
     ]
    }
   ],
   "source": [
    "x_query_train=np.array(query_word2vec_idx_list)[0:74067]\n",
    "x_doc_train=np.array(doc_word2vec_idx_list)[0:74067]#[0:len(x_query_train)]\n",
    "\n",
    "# TODO: replace this with embedding with mask zero rather than padding, need to change index for encoding too, imput dim too.\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_query_train = sequence.pad_sequences(x_query_train, maxlen=query_max_len,padding='post', truncating='post', value=0.)\n",
    "x_doc_train = sequence.pad_sequences(x_doc_train, maxlen=doc_max_len,padding='post', truncating='post', value=0.)\n",
    "# x_query_test = sequence.pad_sequences(x_query_test, maxlen=query_max_len)\n",
    "# x_doc_test = sequence.pad_sequences(x_doc_test, maxlen=doc_max_len)\n",
    "\n",
    "print('x_query_train shape:', x_query_train.shape)\n",
    "print('x_doc_train shape:', x_doc_train.shape)\n",
    "# print('x_query_test shape:', x_query_test.shape)\n",
    "# print('x_doc_test shape:', x_doc_test.shape)\n",
    "\n",
    "#TODO: y label on 0-1 scale from 1-3\n",
    "#y_train=(train_query_df['relevance'].as_matrix()-1)/3\n",
    "\n",
    "# TODO: as categorical\n",
    "y_train=to_categorical(train_query_df['relevance_int'].as_matrix(),13)\n",
    "# y_test=test_query_df['relevance_int'].as_matrix()\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(query_word2vec_idx_list,key=len)) \n",
    "len(max(x_query_train,key=len)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_doc_train[100]\n",
    "y_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exact_match_list=[]\n",
    "for i in range(x_query_train.shape[0]):\n",
    "    #print(i)\n",
    "    c1=x_query_train[i]\n",
    "    c2=x_doc_train[i]\n",
    "    #print(c1.shape[0])\n",
    "    #print(c2.shape[0])\n",
    "\n",
    "    c1_inp=np.repeat(c1,c2.shape[0],axis=0)\n",
    "    c1_inp=c1_inp.reshape((c1.shape[0],c2.shape[0]))\n",
    "    #print(c1_inp.shape)\n",
    "    #print(c1_inp)\n",
    "\n",
    "    #print(c2)\n",
    "    c2_inp=np.tile(c2,(c1.shape[0],1))\n",
    "    #print(c2_inp.shape)\n",
    "    #print(c2_inp)    \n",
    "    #print(c1_inp == c2_inp)\n",
    "    exact_match_list+=[(c1_inp == c2_inp).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exact_match_inp_train=np.array(exact_match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74067, 6, 100)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match_inp_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle bracket\n",
      "simpson strong tie 12 gauge angle\n",
      "[ 979 5124 1571 2864 2489    0]\n",
      "[14620   848   473  9621 12823 14014 14380   794  5124  1571   129   324\n",
      "   125     3  2864   490  9621 12823 14014 14380   794   583  5124  1571\n",
      "  2192    93   414  3878   934   197   160   845  1595   977   690    16\n",
      "  2608   264    43   270    66  1505   714    41    14    38    78   204\n",
      "  1571   456  1387   510  3693  6596    49  5124   129  2608  1084    16\n",
      "  2945   714    41   129   562  1270   138  2465   132   590 20849   745\n",
      "   594     2  1571   129     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "[[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_query_df['search_term'][0])\n",
    "print(product_df['product_title'][0])\n",
    "print(x_query_train[i])\n",
    "print(x_doc_train[i])\n",
    "print(exact_match_inp_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 59253 samples, validate on 14814 samples\n",
      "Epoch 1/10\n",
      "141s - loss: 0.0630 - acc: 0.2727 - val_loss: 0.0658 - val_acc: 0.1402\n",
      "Epoch 2/10\n",
      "139s - loss: 0.0604 - acc: 0.3125 - val_loss: 0.0654 - val_acc: 0.1791\n",
      "Epoch 3/10\n",
      "136s - loss: 0.0595 - acc: 0.3270 - val_loss: 0.0643 - val_acc: 0.2153\n",
      "Epoch 4/10\n",
      "132s - loss: 0.0590 - acc: 0.3353 - val_loss: 0.0648 - val_acc: 0.2004\n",
      "Epoch 5/10\n",
      "130s - loss: 0.0585 - acc: 0.3397 - val_loss: 0.0634 - val_acc: 0.2357\n",
      "Epoch 6/10\n",
      "174s - loss: 0.0581 - acc: 0.3477 - val_loss: 0.0639 - val_acc: 0.2209\n",
      "Epoch 7/10\n",
      "133s - loss: 0.0577 - acc: 0.3531 - val_loss: 0.0642 - val_acc: 0.2322\n",
      "Epoch 8/10\n",
      "131s - loss: 0.0573 - acc: 0.3585 - val_loss: 0.0644 - val_acc: 0.2209\n",
      "Epoch 9/10\n",
      "131s - loss: 0.0569 - acc: 0.3637 - val_loss: 0.0634 - val_acc: 0.2393\n",
      "Epoch 10/10\n",
      "218s - loss: 0.0565 - acc: 0.3689 - val_loss: 0.0644 - val_acc: 0.2295\n"
     ]
    }
   ],
   "source": [
    "batch_size=200#2 #200\n",
    "print('Train...')\n",
    "hist=model.fit([x_query_train,x_doc_train,exact_match_inp_train], [y_train],\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          verbose=2,\n",
    "          #validation_data=[x_test, y_test])\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAFNCAYAAABVKNEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe79315fba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['acc']); plt.plot(hist.history['val_acc']);\n",
    "plt.title('model accuracy'); plt.ylabel('accuracy');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss']); plt.plot(hist.history['val_loss']);\n",
    "plt.title('model loss'); plt.ylabel('loss');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=200 #200\n",
    "prediction=model.predict([x_query_train,x_doc_train,exact_match_inp_train],\n",
    "          batch_size=batch_size,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74067, 13)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03997641,  0.00103513,  0.03729727,  0.00056168,  0.09402336,\n",
       "        0.00057674,  0.14152159,  0.00077425,  0.21090187,  0.00030859,\n",
       "        0.21045884,  0.00105888,  0.26150534], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred2relevance(prediction):\n",
    "    orig_labels = [ 1.  ,  1.25 , 1.33 , 1.5 ,  1.67,  1.75,  2. ,   2.25 , 2.33  ,2.5 ,  2.67  ,2.75 ,3.  ]\n",
    "    new_labels= [ 0 , 1 , 2 , 3 , 4 , 5,  6 , 7 , 8,  9, 10 ,11, 12]\n",
    "    orig_labels_prediction=[]\n",
    "    for preds in prediction:\n",
    "        #print(preds)\n",
    "        max_idx=np.argmax(preds)\n",
    "        orig_labels_prediction+=[orig_labels[max_idx]]\n",
    "    return np.array(orig_labels_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig_labels_prediction =  pred2relevance(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_labels_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE = mean_squared_error(train_query_df['relevance'].as_matrix(), orig_labels_prediction)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59858401734415356"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# print(\"Predict\")\n",
    "word_a = 'wood'#raw_input('First word: ')\n",
    "if word_a not in word2idx:\n",
    "    print('\"%s\" is not in the index' % word_a)\n",
    "word_b = 'fan'#raw_input('Second word: ')\n",
    "if word_b not in word2idx:\n",
    "    print('\"%s\" is not in the index' % word_b)\n",
    "output = model.predict([np.asarray([word2idx[word_a]]), np.asarray([word2idx[word_b]])])\n",
    "print('%f' % output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df=test_private_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from search string\n"
     ]
    }
   ],
   "source": [
    "test_query_sentences = []\n",
    "\n",
    "print(\"Parsing sentences from search string\")\n",
    "for query in test_df[\"search_term\"]:\n",
    "    words,vocab = doc_to_wordlist(query, vocab, remove_stopwords=True)\n",
    "    test_query_sentences += [words]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78419"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_query_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78419\n"
     ]
    }
   ],
   "source": [
    "test_query_word2vec_idx_list = query_sent2idx(test_query_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78419\n"
     ]
    }
   ],
   "source": [
    "test_joined_df=test_df.join(product_df.set_index('product_uid'), on='product_uid')\n",
    "\n",
    "test_joined_doc_sentences=[]\n",
    "for doc in test_joined_df['content']:\n",
    "    words,vocab = doc_to_wordlist(doc, vocab, remove_stopwords=True)\n",
    "    test_joined_doc_sentences += [words]\n",
    "    \n",
    "test_doc_word2vec_idx_list = query_sent2idx(test_joined_doc_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_query_test shape: (78419, 6)\n",
      "x_doc_test shape: (78419, 100)\n"
     ]
    }
   ],
   "source": [
    "x_query_test=np.array(test_query_word2vec_idx_list)[0:78419]\n",
    "x_doc_test=np.array(test_doc_word2vec_idx_list)[0:78419]\n",
    "\n",
    "# TODO: replace this with embedding with mask zero rather than padding, need to change index for encoding too, imput dim too.\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "x_query_test = sequence.pad_sequences(x_query_test, maxlen=query_max_len,padding='post', truncating='post', value=0.)\n",
    "x_doc_test = sequence.pad_sequences(x_doc_test, maxlen=doc_max_len,padding='post', truncating='post', value=0.)\n",
    "# x_query_test = sequence.pad_sequences(x_query_test, maxlen=query_max_len)\n",
    "# x_doc_test = sequence.pad_sequences(x_doc_test, maxlen=doc_max_len)\n",
    "\n",
    "print('x_query_test shape:', x_query_test.shape)\n",
    "print('x_doc_test shape:', x_doc_test.shape)\n",
    "\n",
    "#TODO: y label on 0-1 scale from 1-3\n",
    "#y_train=(train_query_df['relevance'].as_matrix()-1)/3\n",
    "\n",
    "# TODO: as categorical\n",
    "#y_test=to_categorical(train_query_df['relevance_int'].as_matrix(),13)\n",
    "# y_test=test_query_df['relevance_int'].as_matrix()\n",
    "#print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78419, 6, 100)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match_list_test=[]\n",
    "for i in range(x_query_test.shape[0]):\n",
    "    #print(i)\n",
    "    c1=x_query_test[i]\n",
    "    c2=x_doc_test[i]\n",
    "    #print(c1.shape[0])\n",
    "    #print(c2.shape[0])\n",
    "\n",
    "    c1_inp=np.repeat(c1,c2.shape[0],axis=0)\n",
    "    c1_inp=c1_inp.reshape((c1.shape[0],c2.shape[0]))\n",
    "    #print(c1_inp.shape)\n",
    "    #print(c1_inp)\n",
    "\n",
    "    #print(c2)\n",
    "    c2_inp=np.tile(c2,(c1.shape[0],1))\n",
    "    #print(c2_inp.shape)\n",
    "    #print(c2_inp)    \n",
    "    #print(c1_inp == c2_inp)\n",
    "    exact_match_list_test+=[(c1_inp == c2_inp).astype(int)]\n",
    "\n",
    "exact_match_inp_test=np.array(exact_match_list_test)\n",
    "exact_match_inp_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 degree bracket\n",
      "[1867 5365  488    0    0    0]\n",
      "[ 1867   399  1191    47   344   652  2876   196  1362  2016   106    65\n",
      "  1271   886  1020  1867   399  1191    90   138   211  2876  1133   439\n",
      "  5102    75    16   114  1716   544  1497   557   492  4695 11148   510\n",
      "   404     8   544   423  2460     5  9686   509   321  1143    65   271\n",
      "   358   311    49  1853   304   481  1180   521   801  1133   551   971\n",
      "    11   883   544  2016  2051  2841   372  1355  3099   127   477  1362\n",
      "  4957   886   399   326     6     3     6     3     2     2     4    28\n",
      "    47   344    15   463   271   311   358   121  7029   761   702   173\n",
      "     3     2     2     4]\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(test_query_df['search_term'][0])\n",
    "print(x_query_test[0])\n",
    "print(x_doc_test[0])\n",
    "print(exact_match_inp_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=200 #200\n",
    "test_prediction=model.predict([x_query_test,x_doc_test,exact_match_inp_test],\n",
    "          batch_size=batch_size,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78419, 13)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.37288789e-02,   1.74667584e-04,   4.28897664e-02,\n",
       "         3.60229242e-05,   9.47519615e-02,   1.39450101e-04,\n",
       "         2.41705105e-01,   3.70574911e-04,   2.88672209e-01,\n",
       "         6.37196354e-05,   1.96962118e-01,   1.92192630e-04,\n",
       "         1.00313239e-01], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_orig_labels_prediction =  pred2relevance(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3300000000000001"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_orig_labels_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64102161798549973"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_RMSE = mean_squared_error(test_df['relevance'].as_matrix(), test_orig_labels_prediction)**0.5\n",
    "test_RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
